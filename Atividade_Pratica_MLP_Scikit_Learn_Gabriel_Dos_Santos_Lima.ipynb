{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3QK3b-mQV7J"
      },
      "source": [
        "# Redes Neurais Artificiais 2024.1\n",
        "\n",
        "\n",
        "## Implementação de Redes Neurais com Sci-Kit Learn\n",
        "\n",
        "* Professora: Elloá B. Guedes (ebgcosta@uea.edu.br)\n",
        "\n",
        "\n",
        "### Contexto: Consumo de Combustível\n",
        "\n",
        "O objetivo desta atividade prática é utilizar as ferramentas de Machine Learning no ambiente Python com o uso das bibliotecas pandas e sci-kit learn para prever o consumo de combustível de veículos.\n",
        "\n",
        "### Base de Dados\n",
        "\n",
        "Disponível em: https://archive.ics.uci.edu/ml/datasets/auto+mpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o6E1MrTQV7P"
      },
      "source": [
        "### Bibliotecas\n",
        "\n",
        "Por hábito, a primeira célula do notebook costuma ser reservada para importação de bibliotecas.\n",
        "A cada biblioteca nova acrescida, é necessário executar a célula para atualização e correta execução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "lJIsAr6zQV7Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtpva5cQV7R"
      },
      "source": [
        "### Abertura do Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, precisamos baixar o _dataset_ para a pasta local, caso ainda não tenha sido feito (necessário em ambientes como o Google Colab):"
      ],
      "metadata": {
        "id": "4lL7j8iTAnbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile('autompg.csv'):\n",
        "  !wget https://raw.githubusercontent.com/uea-geral/rna-mlp-experiments-exercise/main/autompg.csv"
      ],
      "metadata": {
        "id": "ihGDNv7KBBqP"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abra o dataset e visualize o seu cabeçalho, isto é, os primeiros exemplos nele contidos.\n",
        "Isto é útil para checar se a importação foi realizada de maneira adequada e se a disposição dos dados está de acordo para os próximos passos do trabalho."
      ],
      "metadata": {
        "id": "lo4uSps8X-FI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "VgF32440QV7R"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('./autompg.csv', delimiter=\";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCELkgeuQV7R"
      },
      "source": [
        "### Conhecendo o dataset\n",
        "\n",
        "Para praticar conceitos relativos à exploração do conjunto de dados, utilize as células a seguir para prover respostas para as seguintes perguntas:\n",
        "\n",
        "1. Quantos exemplos há no dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "69Bpa3CZQV7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2825d11b-0ce2-4cc2-8683-03b68a42d21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Há 406 exemplos no conjunto de dados.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Há {len(data)} exemplos no conjunto de dados.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Quais os atributos existentes no dataset?"
      ],
      "metadata": {
        "id": "raNy1o14TQhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "YEr0clnPQV7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1b8efa-b40e-4d51-e477-5b6a5a2e809d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 406 entries, 0 to 405\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     406 non-null    float64\n",
            " 2   displacement  406 non-null    float64\n",
            " 3   horsepower    400 non-null    float64\n",
            " 4   weight        406 non-null    float64\n",
            " 5   acceleration  406 non-null    float64\n",
            " 6   modelyear     406 non-null    float64\n",
            " 7   origin        406 non-null    float64\n",
            " 8   name          406 non-null    object \n",
            "dtypes: float64(8), object(1)\n",
            "memory usage: 28.7+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Quais os nomes dos carros existentes no dataset?"
      ],
      "metadata": {
        "id": "PkrTaRYhTR1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "D6JiYGLJQV7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4ac74f-0b20-4ce6-f5e3-3afba8d5e3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nomes:\n",
            "\n",
            "chevrolet chevelle malibu\n",
            "buick skylark 320\n",
            "plymouth satellite\n",
            "amc rebel sst\n",
            "ford torino\n",
            "ford galaxie 500\n",
            "chevrolet impala\n",
            "plymouth fury iii\n",
            "pontiac catalina\n",
            "amc ambassador dpl\n",
            "citroen ds-21 pallas\n",
            "chevrolet chevelle concours (sw)\n",
            "ford torino (sw)\n",
            "plymouth satellite (sw)\n",
            "amc rebel sst (sw)\n",
            "dodge challenger se\n",
            "plymouth 'cuda 340\n",
            "ford mustang boss 302\n",
            "chevrolet monte carlo\n",
            "buick estate wagon (sw)\n",
            "toyota corona mark ii\n",
            "plymouth duster\n",
            "amc hornet\n",
            "ford maverick\n",
            "datsun pl510\n",
            "volkswagen 1131 deluxe sedan\n",
            "peugeot 504\n",
            "audi 100 ls\n",
            "saab 99e\n",
            "bmw 2002\n",
            "amc gremlin\n",
            "ford f250\n",
            "chevy c20\n",
            "dodge d200\n",
            "hi 1200d\n",
            "chevrolet vega 2300\n",
            "toyota corona\n",
            "ford pinto\n",
            "volkswagen super beetle 117\n",
            "plymouth satellite custom\n",
            "ford torino 500\n",
            "amc matador\n",
            "pontiac catalina brougham\n",
            "dodge monaco (sw)\n",
            "ford country squire (sw)\n",
            "pontiac safari (sw)\n",
            "amc hornet sportabout (sw)\n",
            "chevrolet vega (sw)\n",
            "pontiac firebird\n",
            "ford mustang\n",
            "mercury capri 2000\n",
            "opel 1900\n",
            "peugeot 304\n",
            "fiat 124b\n",
            "toyota corolla 1200\n",
            "datsun 1200\n",
            "volkswagen model 111\n",
            "plymouth cricket\n",
            "toyota corona hardtop\n",
            "dodge colt hardtop\n",
            "volkswagen type 3\n",
            "chevrolet vega\n",
            "ford pinto runabout\n",
            "amc ambassador sst\n",
            "mercury marquis\n",
            "buick lesabre custom\n",
            "oldsmobile delta 88 royale\n",
            "chrysler newport royal\n",
            "mazda rx2 coupe\n",
            "amc matador (sw)\n",
            "ford gran torino (sw)\n",
            "plymouth satellite custom (sw)\n",
            "volvo 145e (sw)\n",
            "volkswagen 411 (sw)\n",
            "peugeot 504 (sw)\n",
            "renault 12 (sw)\n",
            "ford pinto (sw)\n",
            "datsun 510 (sw)\n",
            "toyouta corona mark ii (sw)\n",
            "dodge colt (sw)\n",
            "toyota corolla 1600 (sw)\n",
            "buick century 350\n",
            "chevrolet malibu\n",
            "ford gran torino\n",
            "dodge coronet custom\n",
            "mercury marquis brougham\n",
            "chevrolet caprice classic\n",
            "ford ltd\n",
            "plymouth fury gran sedan\n",
            "chrysler new yorker brougham\n",
            "buick electra 225 custom\n",
            "amc ambassador brougham\n",
            "plymouth valiant\n",
            "chevrolet nova custom\n",
            "volkswagen super beetle\n",
            "ford country\n",
            "plymouth custom suburb\n",
            "oldsmobile vista cruiser\n",
            "toyota carina\n",
            "datsun 610\n",
            "maxda rx3\n",
            "mercury capri v6\n",
            "fiat 124 sport coupe\n",
            "chevrolet monte carlo s\n",
            "pontiac grand prix\n",
            "fiat 128\n",
            "opel manta\n",
            "audi 100ls\n",
            "volvo 144ea\n",
            "dodge dart custom\n",
            "saab 99le\n",
            "toyota mark ii\n",
            "oldsmobile omega\n",
            "chevrolet nova\n",
            "datsun b210\n",
            "chevrolet chevelle malibu classic\n",
            "plymouth satellite sebring\n",
            "buick century luxus (sw)\n",
            "dodge coronet custom (sw)\n",
            "audi fox\n",
            "volkswagen dasher\n",
            "datsun 710\n",
            "dodge colt\n",
            "fiat 124 tc\n",
            "honda civic\n",
            "subaru\n",
            "fiat x1.9\n",
            "plymouth valiant custom\n",
            "mercury monarch\n",
            "chevrolet bel air\n",
            "plymouth grand fury\n",
            "buick century\n",
            "chevroelt chevelle malibu\n",
            "plymouth fury\n",
            "buick skyhawk\n",
            "chevrolet monza 2+2\n",
            "ford mustang ii\n",
            "toyota corolla\n",
            "pontiac astro\n",
            "volkswagen rabbit\n",
            "amc pacer\n",
            "volvo 244dl\n",
            "honda civic cvcc\n",
            "fiat 131\n",
            "capri ii\n",
            "renault 12tl\n",
            "dodge coronet brougham\n",
            "chevrolet chevette\n",
            "chevrolet woody\n",
            "vw rabbit\n",
            "dodge aspen se\n",
            "ford granada ghia\n",
            "pontiac ventura sj\n",
            "amc pacer d/l\n",
            "datsun b-210\n",
            "volvo 245\n",
            "plymouth volare premier v8\n",
            "mercedes-benz 280s\n",
            "cadillac seville\n",
            "chevy c10\n",
            "ford f108\n",
            "dodge d100\n",
            "honda accord cvcc\n",
            "buick opel isuzu deluxe\n",
            "renault 5 gtl\n",
            "plymouth arrow gs\n",
            "datsun f-10 hatchback\n",
            "oldsmobile cutlass supreme\n",
            "dodge monaco brougham\n",
            "mercury cougar brougham\n",
            "chevrolet concours\n",
            "buick skylark\n",
            "plymouth volare custom\n",
            "ford granada\n",
            "pontiac grand prix lj\n",
            "chevrolet monte carlo landau\n",
            "chrysler cordoba\n",
            "ford thunderbird\n",
            "volkswagen rabbit custom\n",
            "pontiac sunbird coupe\n",
            "toyota corolla liftback\n",
            "ford mustang ii 2+2\n",
            "dodge colt m/m\n",
            "subaru dl\n",
            "datsun 810\n",
            "bmw 320i\n",
            "mazda rx-4\n",
            "volkswagen rabbit custom diesel\n",
            "ford fiesta\n",
            "mazda glc deluxe\n",
            "datsun b210 gx\n",
            "oldsmobile cutlass salon brougham\n",
            "dodge diplomat\n",
            "mercury monarch ghia\n",
            "pontiac phoenix lj\n",
            "ford fairmont (auto)\n",
            "ford fairmont (man)\n",
            "plymouth volare\n",
            "amc concord\n",
            "buick century special\n",
            "mercury zephyr\n",
            "dodge aspen\n",
            "amc concord d/l\n",
            "buick regal sport coupe (turbo)\n",
            "ford futura\n",
            "dodge magnum xe\n",
            "datsun 510\n",
            "dodge omni\n",
            "toyota celica gt liftback\n",
            "plymouth sapporo\n",
            "oldsmobile starfire sx\n",
            "datsun 200-sx\n",
            "audi 5000\n",
            "volvo 264gl\n",
            "saab 99gle\n",
            "peugeot 604sl\n",
            "volkswagen scirocco\n",
            "honda accord lx\n",
            "pontiac lemans v6\n",
            "mercury zephyr 6\n",
            "ford fairmont 4\n",
            "amc concord dl 6\n",
            "dodge aspen 6\n",
            "ford ltd landau\n",
            "mercury grand marquis\n",
            "dodge st. regis\n",
            "chevrolet malibu classic (sw)\n",
            "chrysler lebaron town @ country (sw)\n",
            "vw rabbit custom\n",
            "maxda glc deluxe\n",
            "dodge colt hatchback custom\n",
            "amc spirit dl\n",
            "mercedes benz 300d\n",
            "cadillac eldorado\n",
            "plymouth horizon\n",
            "plymouth horizon tc3\n",
            "datsun 210\n",
            "fiat strada custom\n",
            "buick skylark limited\n",
            "chevrolet citation\n",
            "oldsmobile omega brougham\n",
            "pontiac phoenix\n",
            "toyota corolla tercel\n",
            "datsun 310\n",
            "ford fairmont\n",
            "audi 4000\n",
            "toyota corona liftback\n",
            "mazda 626\n",
            "datsun 510 hatchback\n",
            "mazda glc\n",
            "vw rabbit c (diesel)\n",
            "vw dasher (diesel)\n",
            "audi 5000s (diesel)\n",
            "mercedes-benz 240d\n",
            "honda civic 1500 gl\n",
            "renault lecar deluxe\n",
            "vokswagen rabbit\n",
            "datsun 280-zx\n",
            "mazda rx-7 gs\n",
            "triumph tr7 coupe\n",
            "ford mustang cobra\n",
            "honda accord\n",
            "plymouth reliant\n",
            "dodge aries wagon (sw)\n",
            "toyota starlet\n",
            "plymouth champ\n",
            "honda civic 1300\n",
            "datsun 210 mpg\n",
            "toyota tercel\n",
            "mazda glc 4\n",
            "plymouth horizon 4\n",
            "ford escort 4w\n",
            "ford escort 2h\n",
            "volkswagen jetta\n",
            "renault 18i\n",
            "honda prelude\n",
            "datsun 200sx\n",
            "peugeot 505s turbo diesel\n",
            "saab 900s\n",
            "volvo diesel\n",
            "toyota cressida\n",
            "datsun 810 maxima\n",
            "oldsmobile cutlass ls\n",
            "ford granada gl\n",
            "chrysler lebaron salon\n",
            "chevrolet cavalier\n",
            "chevrolet cavalier wagon\n",
            "chevrolet cavalier 2-door\n",
            "pontiac j2000 se hatchback\n",
            "dodge aries se\n",
            "ford fairmont futura\n",
            "amc concord dl\n",
            "volkswagen rabbit l\n",
            "mazda glc custom l\n",
            "mazda glc custom\n",
            "plymouth horizon miser\n",
            "mercury lynx l\n",
            "nissan stanza xe\n",
            "honda civic (auto)\n",
            "datsun 310 gx\n",
            "buick century limited\n",
            "oldsmobile cutlass ciera (diesel)\n",
            "chrysler lebaron medallion\n",
            "ford granada l\n",
            "toyota celica gt\n",
            "dodge charger 2.2\n",
            "chevrolet camaro\n",
            "ford mustang gl\n",
            "vw pickup\n",
            "dodge rampage\n",
            "ford ranger\n",
            "chevy s-10\n",
            "\n",
            "Cerca de 312 nomes de carros diferentes.\n"
          ]
        }
      ],
      "source": [
        "names = data['name'].unique()\n",
        "print(f\"Nomes:\\n\")\n",
        "print(\"\\n\".join(names))\n",
        "print(f\"\\nCerca de {len(names)} nomes de carros diferentes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Quais as características do 'chevrolet camaro'?"
      ],
      "metadata": {
        "id": "Eev0Kq7kTVSV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "5Q0nQom2QV7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "15b70b00-7488-4838-e99e-c4004557205f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
              "400  27.0        4.0         151.0        90.0  2950.0          17.3   \n",
              "\n",
              "     modelyear  origin              name  \n",
              "400       82.0     1.0  chevrolet camaro  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1240f312-15c5-4ed5-a0a7-b26bf75e1115\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>modelyear</th>\n",
              "      <th>origin</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>2950.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>chevrolet camaro</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1240f312-15c5-4ed5-a0a7-b26bf75e1115')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1240f312-15c5-4ed5-a0a7-b26bf75e1115 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1240f312-15c5-4ed5-a0a7-b26bf75e1115');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8b13ed31-6004-432e-a714-c4641745de0e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('car_sample')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8b13ed31-6004-432e-a714-c4641745de0e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('car_sample');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "car_sample",
              "summary": "{\n  \"name\": \"car_sample\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"mpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 27.0,\n        \"max\": 27.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cylinders\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"displacement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 151.0,\n        \"max\": 151.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          151.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"horsepower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 90.0,\n        \"max\": 90.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          90.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2950.0,\n        \"max\": 2950.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2950.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acceleration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 17.3,\n        \"max\": 17.3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modelyear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 82.0,\n        \"max\": 82.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          82.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"origin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"chevrolet camaro\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 307
        }
      ],
      "source": [
        "car_sample = data[data['name'] == 'chevrolet camaro']\n",
        "car_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Qual a média de consumo, em galões por litro, dos carros existentes no dataset?"
      ],
      "metadata": {
        "id": "1OD9PhPRTXjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "engXREbqQV7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689ace0a-79e2-4be0-9d60-52eea2d55770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A média de consumo é 23.5146 milhas/galão\n"
          ]
        }
      ],
      "source": [
        "mpg_mean = data['mpg'].mean()\n",
        "print(f\"A média de consumo é {mpg_mean:.4f} milhas/galão\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Considerando que o **galão americano equivale aproximadamente 3,78 litros** e que **1 milha equivale aproximadamente 1,609 KM**, temos:\n",
        "\n",
        "| Fonte: https://www.mpgtolitres.com/mpg-to-kml"
      ],
      "metadata": {
        "id": "nzaC2tEeX1Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mpg_to_kmpl(mpg: float, decimals=2):\n",
        "  return round(mpg * 0.425, decimals) # valor para conversão de MPG para KM/L"
      ],
      "metadata": {
        "id": "G6u8auPqfMSe"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "litres_mean = mpg_to_kmpl(mpg_mean)\n",
        "print(f\"Aplicando a conversão, a média de consumo é {litres_mean} KM/L\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFjwaAmJYCqv",
        "outputId": "89905531-de55-40a3-d1cc-6c3e91128908"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplicando a conversão, a média de consumo é 9.99 KM/L\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P190HrVfQV7T"
      },
      "source": [
        "### Preparação dos dados\n",
        "\n",
        "1. Existem exemplos com dados faltantes. Para fins de simplificação, elimine-os do dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "xt32hfuJQV7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f4e406-7742-4d28-f739-0cc051275502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 exemplos removidos.\n"
          ]
        }
      ],
      "source": [
        "sanitized_data = data.dropna()\n",
        "print(f\"{len(data) - len(sanitized_data)} exemplos removidos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Exclua a coluna com os nomes dos carros"
      ],
      "metadata": {
        "id": "hiEAsYlGcnCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "WLc0D3D3QV7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21cf133a-6967-4ef8-ef20-3e8d0fec5f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colunas remanescentes: mpg, cylinders, displacement, horsepower, weight, acceleration, modelyear, origin\n"
          ]
        }
      ],
      "source": [
        "if 'name' in sanitized_data:\n",
        "  sanitized_data = sanitized_data.drop(columns=['name'])\n",
        "print(f\"Colunas remanescentes: {', '.join(sanitized_data.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Converta mpg para km/l sabendo que: 1 mpg  = 0.425 km/l. Utilize apenas duas casas decimais nesta conversão\n",
        "4. Remova a coluna mpg e insira a coluna kml no dataset."
      ],
      "metadata": {
        "id": "M4OhYAN7cov3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "i6dRCFpfQV7U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "37d3191d-873a-4175-d5d2-96c2db671412"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cylinders  displacement  horsepower  weight  acceleration  modelyear  \\\n",
              "153        4.0          90.0        75.0  2125.0          14.5       74.0   \n",
              "289        4.0         140.0        88.0  2890.0          17.3       79.0   \n",
              "76         8.0         350.0       160.0  4456.0          13.5       72.0   \n",
              "386        4.0         105.0        63.0  2125.0          14.7       82.0   \n",
              "\n",
              "     origin   km/l  \n",
              "153     1.0  11.90  \n",
              "289     1.0   9.48  \n",
              "76      1.0   5.10  \n",
              "386     1.0  16.15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acf0029c-6366-4705-9a94-4839314880d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>modelyear</th>\n",
              "      <th>origin</th>\n",
              "      <th>km/l</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>4.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>2125.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>4.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2890.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>8.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>4456.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>4.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>2125.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acf0029c-6366-4705-9a94-4839314880d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acf0029c-6366-4705-9a94-4839314880d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acf0029c-6366-4705-9a94-4839314880d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3fe585e-bc50-4727-a425-e30723534c18\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3fe585e-bc50-4727-a425-e30723534c18')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3fe585e-bc50-4727-a425-e30723534c18 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"sanitized_data\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"cylinders\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0,\n        \"min\": 4.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"displacement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 120.99414586389432,\n        \"min\": 90.0,\n        \"max\": 350.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          140.0,\n          105.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"horsepower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.54690957270485,\n        \"min\": 63.0,\n        \"max\": 160.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          88.0,\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1098.8603186938728,\n        \"min\": 2125.0,\n        \"max\": 4456.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2125.0,\n          2890.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acceleration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6206994374857628,\n        \"min\": 13.5,\n        \"max\": 17.3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          17.3,\n          14.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"modelyear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.573474244670748,\n        \"min\": 72.0,\n        \"max\": 82.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          79.0,\n          82.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"origin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"km/l\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.618213038250473,\n        \"min\": 5.1,\n        \"max\": 16.15,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          9.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 313
        }
      ],
      "source": [
        "if 'km/l' not in sanitized_data:\n",
        "  sanitized_data['km/l'] = sanitized_data['mpg'].apply(mpg_to_kmpl)\n",
        "  sanitized_data = sanitized_data.drop(columns=['mpg'])\n",
        "\n",
        "sanitized_data.sample(4, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsEeF9OwQV7U"
      },
      "source": [
        "### Organização dos dados para treinamento\n",
        "\n",
        "1. Remova a coluna kml e atribua-a a uma variável Y\n",
        "2. Atribua os demais valores do dataset a uma variável X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-vTqAgGGQV7V"
      },
      "outputs": [],
      "source": [
        "X = sanitized_data.drop(columns=['km/l'])\n",
        "Y = sanitized_data['km/l']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Efetue uma partição holdout 70/30 com o sklearn"
      ],
      "metadata": {
        "id": "oR0-7VQwk6Am"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "MRl5DRUfQV7W"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qSqqc87QV7W"
      },
      "source": [
        "### Treinamento de um modelo de regressão linear\n",
        "\n",
        "1. Importe o modelo da biblioteca sklearn\n",
        "2. Instancie o modelo com parâmetros padrão (default)\n",
        "3. Execute o algoritmo de treinamento com os dados de treino"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "jivrI_HKk-oW"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "J32v0h2iQV7W"
      },
      "outputs": [],
      "source": [
        "lr_model = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training...\n",
        "lr_model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "0J03K8YVmCSW",
        "outputId": "f573bbe8-3c9a-4985-969d-ba0d36c3551b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJNVgIEqQV7W"
      },
      "source": [
        "### Teste do modelo\n",
        "\n",
        "Vamos observar a saída do modelo para um exemplo individual existente nos dados de treino:\n",
        "* Atributos preditores: X_test[2:3]\n",
        "* Atributo alvo: Y_test.iloc[2]\n",
        "* Qual o resultado previsto para o modelo, dados estes atributos preditores?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ZyXPXh9TQV7W"
      },
      "outputs": [],
      "source": [
        "Y_predict_sample = lr_model.predict(X_test[2:3])\n",
        "Y_true_sample = Y_test.iloc[2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Valor predito: {Y_predict_sample[0]:.2f} KM/L\")\n",
        "print(f\"Valor previsto: {Y_true_sample} KM/L\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucnCVOBRD88-",
        "outputId": "9f10a75e-9fa5-40ee-fc88-c66bdc957477"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valor predito: 12.88 KM/L\n",
            "Valor previsto: 13.6 KM/L\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZJFB3IGQV7W"
      },
      "source": [
        "### Teste do modelo\n",
        "\n",
        "1. Obtenha o R^2 para os dados de teste\n",
        " * Efetue a importação de r2_score do pacote sklearn.metrics\n",
        " * Trata-se de um valor no intervalo [0,1]\n",
        " * Quanto mais próximo de 1, melhor é o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "qAEphgApQV7X"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_predict = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "hFWknK2EITaV"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "AM9kOTKdQV7X"
      },
      "outputs": [],
      "source": [
        "def print_r2_score(y_true, y_predict):\n",
        "  score = r2_score(y_true, y_predict)\n",
        "  print(\"======== Métricas ==========\")\n",
        "  print(f\"R2 Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_r2_score(Y_test, Y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG4U6XmAuWaq",
        "outputId": "85ea4ea0-aa4d-4c8e-a792-2f4a81fc0191"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Métricas ==========\n",
            "R2 Score: 0.8312579780256858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzUKnEF9QV7X"
      },
      "source": [
        "### Obtendo e visualizando os resíduos\n",
        "\n",
        "Uma maneira muito comum de visualizarmos o quão bom certo modelo é para aprender determinados padrões dá-se por meio da visualização dos resíduos, isto é, da diferença entre os valores previstos e observados. Adapte o código a seguir para calcular os resíduos produzidos pelo seu modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "M7J2jtScQV7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08ae984-dd44-4cf8-bf6c-9cc1c8cc1849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6990906201708484,\n",
              " 0.9490029943713353,\n",
              " 0.5220911531088619,\n",
              " 0.05992573247519677,\n",
              " 32.911868347686074,\n",
              " 2.9994766368064973,\n",
              " 0.019264346689764587,\n",
              " 0.009551804517243655,\n",
              " 0.13999133297350708,\n",
              " 0.014513613239374796,\n",
              " 1.4257166337275855,\n",
              " 2.3364504851318597,\n",
              " 2.0816866390879256,\n",
              " 0.7136909365039603,\n",
              " 0.5973653197149701,\n",
              " 2.5964005209039085,\n",
              " 0.01876092250305292,\n",
              " 0.8485366455484642,\n",
              " 2.384224909395687,\n",
              " 0.30254775656468125,\n",
              " 1.1850101728991904,\n",
              " 2.7438169630775806,\n",
              " 0.7912559737221236,\n",
              " 0.30591443089662856,\n",
              " 2.2727398961227316,\n",
              " 2.224863942866946,\n",
              " 2.8741045571918615,\n",
              " 0.05919277050717478,\n",
              " 4.025623246598047,\n",
              " 0.23419655241464007,\n",
              " 0.27229847848789973,\n",
              " 0.01209813031632809,\n",
              " 1.888691430253401,\n",
              " 5.33659761279915,\n",
              " 0.14401553270708223,\n",
              " 1.0231948186680309,\n",
              " 1.6628015050600102,\n",
              " 0.04691000273183324,\n",
              " 0.2582318090550941,\n",
              " 1.8376656294671199,\n",
              " 1.6219159661613605,\n",
              " 0.5731998381213179,\n",
              " 0.015273823466600516,\n",
              " 0.28143953544002837,\n",
              " 0.2562318421570237,\n",
              " 0.6111801057589601,\n",
              " 0.09272662993823794,\n",
              " 0.0387201897871599,\n",
              " 0.0031219508894513256,\n",
              " 0.7214859953372934,\n",
              " 1.0539612546495207,\n",
              " 0.04108014644647068,\n",
              " 0.06932237666434601,\n",
              " 0.350236265857942,\n",
              " 0.9889603792103413,\n",
              " 6.585202796684015,\n",
              " 2.6052155232469656,\n",
              " 2.5823809595027623,\n",
              " 2.961477758622498,\n",
              " 0.007148153119591239,\n",
              " 0.3840713458090052,\n",
              " 0.4696051728764483,\n",
              " 0.24979389166994614,\n",
              " 0.9981329886344608,\n",
              " 23.676692866267523,\n",
              " 1.8003298129390752,\n",
              " 1.1131791881832902,\n",
              " 0.8678123485166167,\n",
              " 2.290683730358106,\n",
              " 0.11124380832986044,\n",
              " 0.1384819340857355,\n",
              " 0.06307785534118779,\n",
              " 0.04072013004818684,\n",
              " 0.40010787522686114,\n",
              " 1.4883335994305662,\n",
              " 1.2636345450402708,\n",
              " 0.4276855190408854,\n",
              " 2.7010219073321062,\n",
              " 2.458134539018062,\n",
              " 0.8906753234165485,\n",
              " 3.885358164985505,\n",
              " 3.542402605736323,\n",
              " 1.535909717640939,\n",
              " 0.4240270485423482,\n",
              " 4.598368707153449,\n",
              " 3.0033983116995073,\n",
              " 1.293950467337508,\n",
              " 5.6486949246100575e-05,\n",
              " 1.1472701197331419,\n",
              " 0.06424521379265737,\n",
              " 1.5523927208908375,\n",
              " 2.7433334684615573,\n",
              " 6.042994862828679,\n",
              " 1.804977198760556,\n",
              " 1.9843954687588126,\n",
              " 1.3707427071258174,\n",
              " 1.8367289610653588,\n",
              " 0.00010379824790341906,\n",
              " 3.5460055664360013,\n",
              " 0.023563496093258758,\n",
              " 6.195076794393578,\n",
              " 1.8559087622480774,\n",
              " 1.3280207907011417,\n",
              " 1.2007360034433097,\n",
              " 0.0988827230170389,\n",
              " 0.0006497341823520942,\n",
              " 3.816294110816741,\n",
              " 0.0004058461734921346,\n",
              " 1.1480141775001442,\n",
              " 2.1820660875639497,\n",
              " 1.0891119035778285,\n",
              " 0.3021050226551851,\n",
              " 0.34815759205666486,\n",
              " 2.766245660154205,\n",
              " 0.8966172494695382,\n",
              " 1.0887206485507621,\n",
              " 0.2048093645369026,\n",
              " 0.6492189432710804]"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ],
      "source": [
        "residuos = []\n",
        "for (x,y) in zip(Y_test,Y_predict):\n",
        "    residuos.append((x-y)**2)\n",
        "residuos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "L4BJaS7pQV7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "70e40832-56c5-4940-ddac-5d6574362161"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA77klEQVR4nO3de3wU1cH/8e8mQEBJggmXEBIu3sAblqLQcLEoKKCFYKAqylNQ1EcMlotFxUdFXu1PFGtFK4q9CPpYoIARFAsUkETUgBWkitIUKEKABBWfJFwkwWR+f6y7ZMleZjezl1k+79drX7CzZ2fP7Ozu+ebMmTMOwzAMAQAA2FBCtCsAAAAQKoIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwLYIMAACwrSbRrkC41dXV6eDBg0pOTpbD4Yh2dQAAgAmGYejIkSPKzMxUQoLvfpe4DzIHDx5UdnZ2tKsBAABCUFpaqqysLJ+Px32QSU5OluR8I1JSUqJcGwAAYEZVVZWys7Pd7bgvcR9kXIeTUlJSCDIAANhMoGEhDPYFAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2RZABAAC2Ffcz+wIAgDCorZU2bpTKyqT27aX+/aXExIhXgyADAACCU1AgTZok7d9/allWlvTcc1JeXkSrwqElAABgXkGBNGqUZ4iRpAMHnMsLCiJaHYIMAAAwp7bW2RNjGA0fcy2bPNlZLkIIMgAAwJyNGxv2xNRnGFJpqbNchBBkAACAOWVl1pazAEEGAACY0769teUsQJABAADm9O/vPDvJ4fD+uMMhZWc7y0UIQQYAAJiTmOg8xVpqGGZc9+fMieh8MgQZAABgXl6etGyZ1KGD5/KsLOfyCM8jw4R4AAAgOHl5Um4uM/sCAACbSkyUBgyIdi04tAQAAOyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGyLIAMAAGwrqkHmpZdeUvfu3ZWSkqKUlBTl5ORo1apV7sdPnDih/Px8paenq2XLlho5cqQOHToUxRoDAIBYEtUgk5WVpSeffFJbtmzRxx9/rGuuuUa5ubn6/PPPJUlTpkzR22+/raVLl6qoqEgHDx5UXl5eNKsMAABiiMMwDCPalagvLS1NTz/9tEaNGqU2bdpo4cKFGjVqlCTpX//6ly666CIVFxfrJz/5ian1VVVVKTU1VZWVlUpJSQln1QEAgEXMtt8xM0amtrZWixcv1rFjx5STk6MtW7bo5MmTGjRokLtMt27d1LFjRxUXF/tcT3V1taqqqjxuAAAgPkU9yHz22Wdq2bKlkpKSdM899+jNN9/UxRdfrPLycjVr1kytWrXyKN+uXTuVl5f7XN+sWbOUmprqvmVnZ4d5CwAAQLREPch07dpV27Zt0+bNmzVhwgSNHTtWX3zxRcjrmz59uiorK9230tJSC2sLAABiSZNoV6BZs2Y6//zzJUk9e/bUP/7xDz333HO6+eabVVNTo4qKCo9emUOHDikjI8Pn+pKSkpSUlBTuagMAgBgQ9R6Z09XV1am6ulo9e/ZU06ZNtX79evdjJSUl2rdvn3JycqJYQwAAECui2iMzffp0DR06VB07dtSRI0e0cOFCFRYWas2aNUpNTdX48eM1depUpaWlKSUlRffdd59ycnJMn7EEAADiW1SDzFdffaVf/OIXKisrU2pqqrp37641a9bo2muvlSQ9++yzSkhI0MiRI1VdXa3BgwfrxRdfjGaVAQBADIm5eWSsxjwyAADYj+3mkQEAAAgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANgWQQYAANhWVIPMrFmzdOWVVyo5OVlt27bViBEjVFJS4lFmwIABcjgcHrd77rknSjUGAACxJKpBpqioSPn5+dq0aZPWrl2rkydP6rrrrtOxY8c8yt11110qKytz32bPnh2lGgMAgFjSJJovvnr1ao/7CxYsUNu2bbVlyxZdddVV7uVnnXWWMjIyIl09AAAQ42JqjExlZaUkKS0tzWP5X/7yF7Vu3VqXXnqppk+fruPHj/tcR3V1taqqqjxuAAAgPkW1R6a+uro6TZ48WX379tWll17qXn7rrbeqU6dOyszM1KeffqoHH3xQJSUlKigo8LqeWbNmaebMmZGqNgAAiCKHYRhGtCshSRMmTNCqVav0/vvvKysry2e5d999VwMHDtSuXbt03nnnNXi8urpa1dXV7vtVVVXKzs5WZWWlUlJSwlJ3AABgraqqKqWmpgZsv2OiR2bixIlauXKl3nvvPb8hRpJ69+4tST6DTFJSkpKSksJSTwAAEFuiGmQMw9B9992nN998U4WFherSpUvA52zbtk2S1L59+zDXDgAAxLqoBpn8/HwtXLhQK1asUHJyssrLyyVJqampatGihXbv3q2FCxfq+uuvV3p6uj799FNNmTJFV111lbp37x7NqgMAgBgQ1TEyDofD6/L58+dr3LhxKi0t1ZgxY7R9+3YdO3ZM2dnZuvHGG/XII4+YHu9i9hgbAACIHbYYIxMoQ2VnZ6uoqChCtQEAAHYTU/PIAAAABCMmzloCAABhUlsrbdwolZVJ7dtL/ftLiYnRrpVlCDIAAMSrggJp0iRp//5Ty7KypOeek/LyolcvC3FoCQCAeFRQII0a5RliJOnAAedyHzPk2w1BBgCAeFNb6+yJ8XZSjWvZ5MnOcjZHkAEAIN5s3NiwJ6Y+w5BKS53lbI4gAwBAvCkrs7ZcDCPIAAAQb8xexicOLvdDkAEAIN707+88O8nHDPpyOKTsbGc5myPIAAAQbxITnadYSw3DjOv+nDlxMZ8MQQYAgHiUlyctWyZ16OC5PCvLuTxO5pFhQjwAAOJVXp6Um8vMvgAAwKYSE6UBA6Jdi7Dh0BIAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALAtggwAALCtqAaZWbNm6corr1RycrLatm2rESNGqKSkxKPMiRMnlJ+fr/T0dLVs2VIjR47UoUOHolRjAAAQS6IaZIqKipSfn69NmzZp7dq1OnnypK677jodO3bMXWbKlCl6++23tXTpUhUVFengwYPKy8uLYq0BAECscBiGYUS7Ei5ff/212rZtq6KiIl111VWqrKxUmzZttHDhQo0aNUqS9K9//UsXXXSRiouL9ZOf/CTgOquqqpSamqrKykqlpKSEexMAAIAFzLbfMTVGprKyUpKUlpYmSdqyZYtOnjypQYMGuct069ZNHTt2VHFxsdd1VFdXq6qqyuMGAADiU8wEmbq6Ok2ePFl9+/bVpZdeKkkqLy9Xs2bN1KpVK4+y7dq1U3l5udf1zJo1S6mpqe5bdnZ2uKsOAACiJGaCTH5+vrZv367Fixc3aj3Tp09XZWWl+1ZaWmpRDQEAQKxpEu0KSNLEiRO1cuVKvffee8rKynIvz8jIUE1NjSoqKjx6ZQ4dOqSMjAyv60pKSlJSUlK4qwwAAGJAVHtkDMPQxIkT9eabb+rdd99Vly5dPB7v2bOnmjZtqvXr17uXlZSUaN++fcrJyYl0dQEAQIyJao9Mfn6+Fi5cqBUrVig5Odk97iU1NVUtWrRQamqqxo8fr6lTpyotLU0pKSm67777lJOTY+qMJQAAEN+ievq1w+Hwunz+/PkaN26cJOeEePfff78WLVqk6upqDR48WC+++KLPQ0un4/RrAADsx2z7HVPzyIQDQQYAAPux5TwyAAAAwSDIAAAA27IsyFRUVFi1KgAAAFNCCjJPPfWU/vrXv7rv33TTTUpPT1eHDh30z3/+07LKAQAA+BNSkJk3b5576v+1a9dq7dq1WrVqlYYOHapp06ZZWkEAAABfQppHpry83B1kVq5cqZtuuknXXXedOnfurN69e1taQQAAAF9C6pE555xz3NcwWr16tfvq1IZhqLa21rraAQAA+BFSj0xeXp5uvfVWXXDBBTp8+LCGDh0qSfrkk090/vnnW1pBAAAAX0IKMs8++6w6d+6s0tJSzZ49Wy1btpQklZWV6d5777W0ggAAAL4wsy8AAIg5ZtvvkC8auXv3bs2ZM0c7duyQJF188cWaPHmyzj333FBXCQAAEJSQBvuuWbNGF198sT766CN1795d3bt31+bNm3XxxRdr7dq1VtcRAADAq5AOLfXo0UODBw/Wk08+6bH8oYce0t///ndt3brVsgo2FoeWAACwn7BeNHLHjh0aP358g+V33HGHvvjii1BWCQAAELSQgkybNm20bdu2Bsu3bdumtm3bNrZOAAAApoQ02Peuu+7S3Xffrf/85z/q06ePJOmDDz7QU089palTp1paQQAAAF9CGiNjGIbmzJmjZ555RgcPHpQkZWZmatq0afrlL38ph8NheUVDxRgZAADsx2z73eh5ZI4cOSJJSk5ObsxqwoYgAwCA/YR9HhmXWA0wAAAg/oUUZLp06eL38NF//vOfkCsEAABgVkhBZvLkyR73T548qU8++USrV6/WtGnTrKgXAABAQCEFmUmTJnldPnfuXH388ceNqhAAAIBZIc0j48vQoUP1xhtvWLlKAAAAnywNMsuWLVNaWpqVqwQAAPAppENLPXr08BjsaxiGysvL9fXXX+vFF1+0rHIAAAD+hBRkRowY4XE/ISFBbdq00YABA9StWzcr6gUAABBQoyfEi3VMiAcAgP1YPiFeVVWV6RcnMAAAgEgwHWRatWpl+hpKtbW1IVcIAADALNNBZsOGDe7/f/nll3rooYc0btw45eTkSJKKi4v16quvatasWdbXEgAAwIuQxsgMHDhQd955p0aPHu2xfOHChfrDH/6gwsJCq+rXaIyRAQDAfsy23yHNI1NcXKwrrriiwfIrrrhCH330USirBAAACFpIQSY7O1t//OMfGyz/05/+pOzs7EZXCgAAwIyQ5pF59tlnNXLkSK1atUq9e/eWJH300UfauXMnlygAAAARE1KPzPXXX69///vfGjZsmL799lt9++23GjZsmP7973/r+uuvt7qOAAAAXpka7LtixQrl5OSobdu2kaiTpRjsCwCA/Vg6IV51dbX69eunVatW6bzzztOnn37qt3z37t2Dqy0AAEAITAWZm266SSkpKfrZz36mHTt26Ec/+pEcDoe8deY4HA4mxAMAABFherDvkCFD3BeE3LNnT9gqBAAAYFZQZy117txZktSpU6dw1AUAACAoIZ219Oqrr+qdd95x33/ggQfUqlUr9enTR3v37jW9nvfee0/Dhg1TZmamHA6Hli9f7vH4uHHj5HA4PG5DhgwJpcoAACAOhRRknnjiCbVo0UKSc5bfF154QbNnz1br1q01ZcoU0+s5duyYLr/8cs2dO9dnmSFDhqisrMx9W7RoUShVBgAAcSikCfFKS0t1/vnnS5KWL1+uUaNG6e6771bfvn01YMAA0+sZOnSohg4d6rdMUlKSMjIyQqkmAACIcyH1yLRs2VKHDx+WJP3973/XtddeK0lq3ry5vvvuO+tqJ6mwsFBt27ZV165dNWHCBPfr+lJdXa2qqiqPGwAAiE8h9chce+21uvPOO9WjRw+P2Xw///xz94BgKwwZMkR5eXnq0qWLdu/erYcfflhDhw5VcXGxEhMTvT5n1qxZmjlzpmV1AAAAsSukHpm5c+cqJydHX3/9td544w2lp6dLkrZs2aLRo0dbVrlbbrlFw4cP12WXXaYRI0Zo5cqV+sc//qHCwkKfz5k+fboqKyvdt9LSUsvqAwAAYktIPTKtWrXSCy+80GB5uHtCzj33XLVu3Vq7du3SwIEDvZZJSkpSUlJSWOsBAABiQ0g9MpK0ceNGjRkzRn369NGBAwckSf/7v/+r999/37LKnW7//v06fPiw2rdvH7bXAAAA9hFSkHnjjTc0ePBgtWjRQlu3blV1dbUkqbKyUk888YTp9Rw9elTbtm3Ttm3bJDlnDN62bZv27duno0ePatq0adq0aZO+/PJLrV+/Xrm5uTr//PM1ePDgUKoNAADiTEhB5je/+Y3mzZunP/7xj2ratKl7ed++fbV161bT6/n444/Vo0cP9ejRQ5I0depU9ejRQ4899pgSExP16aefavjw4brwwgs1fvx49ezZUxs3buTQEQAAkBTiGJmSkhJdddVVDZanpqaqoqLC9HoGDBjg9cKTLmvWrAmlegAA4AwRUo9MRkaGdu3a1WD5+++/r3PPPbfRlQIAADAjpCBz1113adKkSdq8ebMcDocOHjyov/zlL7r//vs1YcIEq+sIAADgVUiHlh566CHV1dVp4MCBOn78uK666iolJSVp2rRpuvPOO62uIwAAgFch9cg4HA79z//8j7799ltt375dmzZt0tdff63U1FR16dLF6joCAAB4FVSQqa6u1vTp03XFFVeob9+++tvf/qaLL75Yn3/+ubp27arnnnsuqKtfAwAANEZQh5Yee+wxvfzyyxo0aJA+/PBD/fznP9ftt9+uTZs26ZlnntHPf/5zn9dAAgAAsFpQQWbp0qV67bXXNHz4cG3fvl3du3fX999/r3/+859yOBzhqiMAAIBXQR1a2r9/v3r27ClJuvTSS5WUlKQpU6YQYgAAQFQEFWRqa2vVrFkz9/0mTZqoZcuWllcKAADAjKAOLRmGoXHjxrkvEXDixAndc889Ovvssz3KFRQUWFdDAAAAH4IKMmPHjvW4P2bMGEsrAwAAEIyggsz8+fPDVQ8AAICghTQhHgAAQCwgyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANsiyAAAANuKapB57733NGzYMGVmZsrhcGj58uUejxuGoccee0zt27dXixYtNGjQIO3cuTM6lQUAADEnqkHm2LFjuvzyyzV37lyvj8+ePVvPP/+85s2bp82bN+vss8/W4MGDdeLEiQjXFAAAxKIm0XzxoUOHaujQoV4fMwxDc+bM0SOPPKLc3FxJ0muvvaZ27dpp+fLluuWWWyJZVQAAEINidozMnj17VF5erkGDBrmXpaamqnfv3iouLvb5vOrqalVVVXncAABAfIrZIFNeXi5Jateuncfydu3auR/zZtasWUpNTXXfsrOzw1pPAAAQPTEbZEI1ffp0VVZWum+lpaXRrhIAAAiTmA0yGRkZkqRDhw55LD906JD7MW+SkpKUkpLicQMAAPEpZoNMly5dlJGRofXr17uXVVVVafPmzcrJyYlizQAAQKyI6llLR48e1a5du9z39+zZo23btiktLU0dO3bU5MmT9Zvf/EYXXHCBunTpokcffVSZmZkaMWJE9CoNAABiRlSDzMcff6yrr77afX/q1KmSpLFjx2rBggV64IEHdOzYMd19992qqKhQv379tHr1ajVv3jxaVQYAADHEYRiGEe1KhFNVVZVSU1NVWVnJeBkAAGzCbPsds2NkAAAAAiHIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA2yLIAAAA22oS7QoAANBotbXSxo1SWZnUvr3Uv7+UmBjtWiECCDIAAHsrKJAmTZL27z+1LCtLeu45KS8vevVCRHBoCQBgXwUF0qhRniFGkg4ccC4vKIhOvRAxBBkAgD3V1jp7Ygyj4WOuZZMnO8shbhFkAHiqrZUKC6VFi5z/0gggVm3c2LAnpj7DkEpLneUQtxgjA+AUxhogkho7QLeszNpysCV6ZAA4MdYAkVRQIHXuLF19tXTrrc5/O3cO7nPWvr215WBLDsPwdnAxflRVVSk1NVWVlZVKSUmJdnWA2FRb62xEfHXTOxzOnpk9ezilFY3nCs2nNz8Oh/PfZcvM9QC6PrcHDngfJ8Pn1tbMtt/0yABgrAEix8oBuomJzsOe0qkQ5OK6P2cOISbOEWQAMNYAkWN1aM7Lc/bgdOjguTwry3zPDmyNwb4AGGuAyAlHaM7Lk3Jzmdn3DEWQAeD80c/KCjzWoH//yNcN8SVcoTkxURowIOjqwP44tAQguLEGzDODxnCF5tM/Zy4Oh5SdTWiGaQQZAE5mxhpYccoszmwM0IXFOP0agCdfk5RZdcosIHmffDE72xli+BxB5ttvggyAwJhnBuHQ2Jl9EdfMtt8M9gUQWDCnzDLgEmYxQBcWiOkxMo8//rgcDofHrVu3btGuFnDmYZ4ZADEq5ntkLrnkEq1bt859v0mTmK8yEH+YZwZAjIr5VNCkSRNlZGREuxrAmY15ZgDEqJg+tCRJO3fuVGZmps4991zddttt2rdvn9/y1dXVqqqq8rgBaKRAp8wahnTnndKSJcwtAyCiYvqspVWrVuno0aPq2rWrysrKNHPmTB04cEDbt29XcnKy1+c8/vjjmjlzZoPlnLUEWMDbKbPp6c5/Dx8+tSwryxl8OI0WQIji8vTriooKderUSb/73e80fvx4r2Wqq6tVXV3tvl9VVaXs7GyCDGCV+qfM7twpPf44c8sAsFxcnn7dqlUrXXjhhdq1a5fPMklJSUpKSopgrYAzjOuUWdfcMt7+FjIMZ5iZPNl5MT/mBgEQJjE/Rqa+o0ePavfu3WrPmRFA9AUztwwAhElMB5lf/epXKioq0pdffqkPP/xQN954oxITEzV69OhoVw0Ac8sAiAExfWhp//79Gj16tA4fPqw2bdqoX79+2rRpk9q0aRPtqgG+nSnTrjO3DIAYYKvBvqHgWkuIKG9n9cTrGTyuMTKB5pbxdv2lMyXsAQiZ2fY7pg8tAbbiujr06eNGDhxwLi8oiE69wiXQ3DKS80rGpweUggJnALr6aunWW53/du4cf+9PJNTWOuftWbSI+XtwxiLIAFaorXX2xPg6g0dynsETbw1NXp7zFOsOHTyXZ2V5P/X6TAt74UQgBCRxaAmwRmGhsyEJZMOG+Lzar5lDRa5DUb7OdPJ3KAqeXIGQ+XsQx+JyHhkgZp3pZ/C45pbxJ5jTteMx7FklUO9frM7fE+y4KMZRwSQOLQFW4AyewM70sGcVO87fE+xhMA6bIQgEGcAKrqtDnz7o1cXhkLKzz+yrQxP2rGG3QBjsuCjGUSFIBBnACqGewXMmIexZw06BMNhB8GfqoHk0CkEGsEqwZ/CcaQh71rBTIAz2MJgdD5sh6ggygJXy8qQvv3SenbRwofPfPXsIMS6RCntWzq8Sa3O12CkQBnsYzG6HzRATCDIAIivcYc/KgaKxOujULr1/wR4Gs9NhM8QM5pEBrHQmXaIgFlk5v4od5mqpqZFefFHavVs67zzp3nulZs2iW6f6gr2MRWMue4G4Y7b9JsgAVrFDwxcNZifLa+ycIVZOuBfrk/fV1kr/7/85A/K3355aHouh2fW9kDy/G76+F8GWDwVz1NiC6fbbiHOVlZWGJKOysjLaVUE8+/57w8jKMgznT2/Dm8NhGNnZznLx4vvvDWPDBsN4/XXDePZZ578bNnhu4xtvNHxfsrKcy4MpY8aGDb7f//q3DRsiuy6rvfGGYaSn+/6cORzBv3fh5m0fZ2f7rmew5Rtbl1A+bwg7s+03PTKAFc60SxR4O4Tm4uoVkAL3UJkpY/av70WLnONYApk4URo50v9f4WbXtXChNHq0ufpZwVevX33R7i3yJRZm9qXX1FY4tPQDggwiIlYbvnAw25impUmHD/t+3DVQ1arDN2bDpIu/wzCxGEwDHe46XbyEZqvE+uFCNGC2/easJcAKZ8rZFv4mLKvPMHyHGNfj+/dbM2eI6/ToAwek1q39l63P30yxsThXS6A5Vk7HKcqemKMmbhFkACv07y+lp/svk54efMMXa3OYBNuYWsFfg1z/9OgxY6RvvjG/Xn8zxcbiXC3BBhO7h2arMUdN3CLIAFaprvb/eE1NcOuLxTlMovEj37at9+W+rskTDH9/hcfaXC3BBJNYmdk3lpwpvaZnIIIMYIXCQunoUf9ljhxxljMjVi+cZ9WPvGs8gr/DNy7jxjXc3kCHuBwOqU0b57wqZvgKaLE0U3Ogw131xcrMvrGittZ5S0vzXSaWLu2AoBBkACu8+6515cJ54bzGHqrq08dcA+lwnDrU5uvQzHPP+T58U5+38GZmvMPXX0sXXBC4rpL/gJaY6Bw0O3q0899oBQR/h7tc0tOlN97gzJv6XD2bgwZ5zrlTX6xd2gFBIcgAVti3z7pyVg1KPD20LFsmderkeaiqU6fgenc+/NBc+DEM6Q9/cDaq/g7NuA7fZGb6X5fkGd7MHuJq0yZ8g3ajMX7J1+Gu9HRp5kzp0KHYCTGxML7L7OHHWLu0A4LSJNoVAGJCY+es6NjRunJWDEr0N89LfQcOOOdUMftXvNm6TZ58an25uf7f27w8KTXV+RezL/XD24AB5g9xdejg7MUYNcoZWrzNFBvKX+HRvBRFXl7g9zTaYuFSHWbOsEtLk5YsiW5PGxovApPzRRUz+yIgszN9umayXbiw4Qy269aZmwl23brA9WnsrLJvvOGc3dXMOly3li1PbY+/7QzXjLcLF5pb78KFp+qYleV7O0+fSdnKmWJ9vb+xOqtupMXK+xPLszPDFLPtN0EGZzazP7qBws733/ueNt51S083d4mCYBtpb88NJsS4bmvWmNvOUOvmj9kgWL/Rce270+viq8H0F9DMOhMvRRGMWHp/gg3HiDkEmR8QZOCT2R/dJUvMhx1/P5jB/CXqr5GWDGPmzMb1mHi7XXWV+e0MJkCY2dYOHfzXzVcDGM5r8rjUD0DPPht84DqTxFIvSCzVBSEhyPyAIAOfzP7QtW5tvoG18oJ03taVnt6w56f++s3+Fert1rx547bTFfqC6fUwcxgsUECyoqfFX/1C6eE6U//Kj6VekEC9h5JhtGljGNXV4a8LQsJFI3/AtZbilBUXlDN7fSQz6l/XxsqL3dVf186d0uOPO3+C66t/wbu0tOCuNxQsf9v5zTfSlCnmB3iavXZQpAeJupi5ppQvdrzOkRWf21i7RpVrH0q+92O0Pl8IyHT7HZFYFUX0yMQhq3o9GnMYxoq/MIPpSTB7GKy6OvBfoeHYzlAGeJp9/80MkG7Me+vr+aH0xNh1jIwVA95dj4djDFVjBOpVY5B2zOLQ0g8IMnHGyjMizPzotmljrgGrf5zdTCMabMPxyCPm6+FrDIsVN2/jCUId4BmuwxChBt1QxsLEQ4No1YD309dn1Rgql8aE0+pq/99luwbQOEeQ+QFBJo6E44yIQD+6S5cGf5rv6QNXO3Tw/PFuTMNhttEP5bmtW4f2l3SogyrDMRgz1KAb6liY+jcrBxmHc9zP6a9j5ju1dGlw76vVg7Ab2wvLwF9bIsj8gCATR8L1YxToR9fs2UhmyjW24Qh0e+SRUw2fqzF8/XXDSEnx/7z09FNnZwX7l3SoPStWH4YINeiGMu+O6/bMM9aHDSsHjAcKRGa/U6H0ZlgVxsyGU3+vF0uDkGEaQeYHBJk4Es4fI38/gmYDipl5ZMzOl2L2kJavW6hz3ITyl3RjAqaVc8GEUo/GzLsjhTZ+xx8rD52aCUSNOcvNzP5trGCmSPC3rfTI2BJB5gcEmTgSjR8jsyFgzRpzdXv4YesaDn+3+g1fsO9b/Z6cZ591/uvvL+rG9qyYDU+BGuZQgm5jB3zXX1e4Bxi7xmwF2h+u98pMIIr2gPdAGlO/+tsai4OQERBB5gcEmTgSjR8jsz0ot95qrtyYMdY1HGZ+yLOznQ1fsA1RsIc3GjvAM1AIMNMwhxJ0G9sj4VqXFYeDgm20fa0/mENsVg54f/ZZ6w+zNXb/1N/WcA1CRtgQZH5AkIkzkf4xMnu2UN++5so9/LB1DYfZUBTsbLRWDpi1YgBssKee+9vG04NuqH/xe2sgzb5fvkJbsI22r/UHG+gCfadch238jSNKTPS8H+qYntNZ1WPkL3BaPRM0LEOQ+QFBJg6F48fIV+NiNsjcdpu5cuvWNb7hCLan5bXXGjY03hqi6urGnxkWjrNtgmmYp03zX2batIb1DXbeHW+HLPyVz8o69T4sWdJwpmhXox9qo3364aZQDrFNm9bwM5KYeOr9CvaUfqv+sAhl/wTa1kidEYZGI8j8gCATp6z8MfJ3WODvfzf3Q7l6dXAXjTRzplSgniezDV8wPTLRGhRpxRknr78efI9MoPdaMoyEBN8NvNn3a9Qow7j5Zv8Nf6BT/c3csrKc1+EKZh8uWeK/Xv6mA/AXkK061Bto/0Tj84qIIMj8gCADvwIdFpgxw9wPpaunxV+ZYGdJDfRXstkxQ8GMkYnGaaqBxpeEI7Cdvg8mT254SM9fMHU18Fae9VP/AqWhhhnXcwOFasn5WkuXBhdGwnEBzVAnkHRNU8Ag3rhltv1uEo7rIwC2UFsrTZrk/Mk7nWE4r2H0wgvm1vXVV1JSkv8y27dL1dWe17Hxdb2ZggLpt79tWLfaWunpp6WWLaULLpDuukuaMcNZ1/plXddfmjPHef0lM9q3N1cu2LL+ruHj63pGBw44ly9bJuXmSunp0uHDvl8jPV1q08ZcfcrKTr32pEme13pq3VoaM0b62c+ksWP9r2fyZOmOO8y9phmlpc5tWLZM+uUvne9BsFyfWzMmTPD/nrrWV1rq3H8DBjj3W//+zvsffmjudVzvtzfe9oG3ax/l5Tk/B94+RwkJzs+Kv+9AqNc6gz1EKFhFDT0y8MnKU0/XrQtuPhJ/Z5ysW2cYaWnm15We3nDCu/qHqcyM4wjmLJZg/sL119sSzCBeK0+BN9N7NnKkdZ+NYG4LFzrrlpkZndf3Vy9f+zPQzVePTLjnzGEQr+3F1aGlF154wejUqZORlJRk9OrVy9i8ebPp5xJk4JPZwwJpaYEbdrOnafv7sbZimnzJOZh0yRLPbQ1mEKxVZ4YFaqjMjuUwewhj9mxz5VavNoyWLSMbBMzezL4nkb7Vv4aX2ef4C73huNwIg3jjjtn222EYhhHdPiH//vrXv+oXv/iF5s2bp969e2vOnDlaunSpSkpK1LZt24DPN30ZcJPq6gz93/GaRq8H0ddkY5FSrx8csNzxhx9Vi1m/kSQ56n1djB+6ro/+7yKpplrJd4wN6vUNh0N1mR1U8XmJmq18Wy3/a7RkGDJ5YMDvel31qskdIdXWqtUlFyrhwAGv6zYk1XXIUsXnJe4u+GYrluusB+9XYr3DG7UdsnT8qd861xlIoNd0OGScc44Svv024Kq+u/setfjDvIDlqn82XEkr3wpY7vuuF6lJyY6A5SKtNr21HNUn5Dh61Od+auxnI1iGJCUm6tuyb9Sqx6V+P0P1lzf4DJ7G7Hev8m9r9H3/n4ZQcwTjnLOaKSEh0p+uwMy23zE/RuZ3v/ud7rrrLt1+++2SpHnz5umdd97RK6+8ooceeiji9fm/4zXq+Zt1EX9dWC+hrlbvJ7dWxpFvlODl8TpJ5cmt1e/kFbo2d7pmrP+DMo984368rGW6Zg68W2s+a6mcL3dpUZCv7zAMJR7Yr4n//aye+dscnW0YXusRLIdhqE7SkQkT1e+fLdRr/+da7Ge8hUNS4oH9yp/wnDZ17P7D0pZKuPVF9dr/udoe/T991fIcfZR1ieo+S5Q+C/z5/8m+T/2/pmHIYSLESNJvd9boURPlVu6u0kgT5RJiLMS4ovHvL7xak4uX+iznambqJL+fkzpJ37ZIVevvKhtdN4ck1dZq7i3T9FiAz1B99b8b3j4vw78o0vMmXv/Rl9bpraKTwVQZIdjyyCCltwwwxi+GxXSQqamp0ZYtWzR9+nT3soSEBA0aNEjFxcVen1NdXa3q6mr3/aqqqrDXE/ZUl5ComQPv1kvLn2jQONT98O/MgXerLiFRa7r20doLejds2BMaP4gwZ99nHgHJCgmSMo98466vGaeXq0tIrBdsgmP2Nf+vebJSTxzxGyT/1aazqXV90baLRu4oDFjOirBotZd75Sm70txnIFD9HZKWXzJAd368otH1culYUW6q3IIf/0yru/YJ+N34quU5ptZnthzObLH4nXb75ptvVFtbq3bt2nksb9euncrLvX+xZs2apdTUVPctOzs7ElWFTa3p2kcTRjys8uTWHsvLk1trwoiHtaZrH/cyV8P+1sU/1aaO3T1+qNscb/xfv+HgCl1mWNlomF3XKz2HSzoVHF3qB8n0746YWtc3yWn6tnmyfB0rNyR9l9jU1Loi5ZuzUnVv7kN68uo7dPbJ7yxZ55+vyNW6C3pbsi6Xfa0yTJVb3bVPg++GNx9lXaKDya0b7HeXOkkHk1vro6xLgqsozkgxHWRCMX36dFVWVrpvpaWl0a4SYtyarn3U754/65bRT+iXw6bpltFPqN89f/YIMYGEEgJcP9bFHS8L+rlmuXqOIt1omH3NuX1uChgkzb63h5LTNX3IfTKkBmHGteyti64KbkMsZkiqatZCk352v24Z/YR65b+mVd36SZI+yrrYktdYd0HvgO+/Wa799FqP6y39DLl6Q13PPX1d0qneUCCQmB7sW1NTo7POOkvLli3TiBEj3MvHjh2riooKrVgRuOuUwb6ICNfg1oMHPQYEu/gdDPmzYX6fG2hdXsvUG0isxEQ1W7HcOZhYvgcsmxrEG4SgXrO2Vk0+fF8J5eWqy8jQ9336nZr7I9B762Vbz3pgqhIPHnSXqc3soOOzn1HN0OuV1qaVVFcXnYGzko6+vtj7e11To7TWqT4HfNffcl8DqE3tc1/Pl/8Bu+H4DDV6UDksYffBvorAGVSN0qtXL2PixInu+7W1tUaHDh2MWbNmmXo+p18jYoK5Hs3pc1wEey2bQKe9ejtNOhpzbVj1msGeEu7vVNxAp6KH62ZmuwPVLTc3uPehMaf0e6tvJK9zhjNe3Mwjs3jxYiMpKclYsGCB8cUXXxh333230apVK6O8vNzU8wkyiChfP/RLloQ2Dfvpt8REw7j//lPrmjnTMDp0MN+wRKPRsOo1rWxEvV3+ISGh4fwy6ekNJ+M7/XnZ2c71eZv4b+bM4Ld72jT/13cK9n04/f13Tet/+vOXLjW3nwgeiJC4mUdGkl544QU9/fTTKi8v149+9CM9//zz6t3b3GA2qw8tAQH5m5I/2Of27i29/LK0e7d03nnSvfdKzZpZ93p2Y+W21tRIL77o+d4mJjZcv+S5rE8f5/T8p9ch3HWrv98b+1pn0mcGtmW2/bZFkGkMggwAAPZjtv2Ou7OWAADAmYMgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbKtJtCsQbq6Ji6uqqqJcEwAAYJar3Q50AYK4DzJHjhyRJGVnZ0e5JgAAIFhHjhxRamqqz8fj/lpLdXV1OnjwoJKTk+VwOCxbb1VVlbKzs1VaWhq313BiG+MD2xgf2Mb4wDaaZxiGjhw5oszMTCUk+B4JE/c9MgkJCcrKygrb+lNSUuL2w+jCNsYHtjE+sI3xgW00x19PjAuDfQEAgG0RZAAAgG0RZEKUlJSkGTNmKCkpKdpVCRu2MT6wjfGBbYwPbKP14n6wLwAAiF/0yAAAANsiyAAAANsiyAAAANsiyAAAANsiyPgxd+5cde7cWc2bN1fv3r310Ucf+S2/dOlSdevWTc2bN9dll12mv/3tbxGqafBmzZqlK6+8UsnJyWrbtq1GjBihkpISv89ZsGCBHA6Hx6158+YRqnHwHn/88Qb17datm9/n2GkfSlLnzp0bbKPD4VB+fr7X8nbYh++9956GDRumzMxMORwOLV++3ONxwzD02GOPqX379mrRooUGDRqknTt3BlxvsN/ncPK3jSdPntSDDz6oyy67TGeffbYyMzP1i1/8QgcPHvS7zlA+7+EUaD+OGzeuQX2HDBkScL122Y+SvH43HQ6Hnn76aZ/rjLX9aKatOHHihPLz85Wenq6WLVtq5MiROnTokN/1hvo99oYg48Nf//pXTZ06VTNmzNDWrVt1+eWXa/Dgwfrqq6+8lv/www81evRojR8/Xp988olGjBihESNGaPv27RGuuTlFRUXKz8/Xpk2btHbtWp08eVLXXXedjh075vd5KSkpKisrc9/27t0boRqH5pJLLvGo7/vvv++zrN32oST94x//8Ni+tWvXSpJ+/vOf+3xOrO/DY8eO6fLLL9fcuXO9Pj579mw9//zzmjdvnjZv3qyzzz5bgwcP1okTJ3yuM9jvc7j528bjx49r69atevTRR7V161YVFBSopKREw4cPD7jeYD7v4RZoP0rSkCFDPOq7aNEiv+u0036U5LFtZWVleuWVV+RwODRy5Ei/642l/WimrZgyZYrefvttLV26VEVFRTp48KDy8vL8rjeU77FPBrzq1auXkZ+f775fW1trZGZmGrNmzfJa/qabbjJuuOEGj2W9e/c2/vu//zus9bTKV199ZUgyioqKfJaZP3++kZqaGrlKNdKMGTOMyy+/3HR5u+9DwzCMSZMmGeedd55RV1fn9XG77UNJxptvvum+X1dXZ2RkZBhPP/20e1lFRYWRlJRkLFq0yOd6gv0+R9Lp2+jNRx99ZEgy9u7d67NMsJ/3SPK2jWPHjjVyc3ODWo/d92Nubq5xzTXX+C0Ty/vRMBq2FRUVFUbTpk2NpUuXusvs2LHDkGQUFxd7XUeo32Nf6JHxoqamRlu2bNGgQYPcyxISEjRo0CAVFxd7fU5xcbFHeUkaPHiwz/KxprKyUpKUlpbmt9zRo0fVqVMnZWdnKzc3V59//nkkqheynTt3KjMzU+eee65uu+027du3z2dZu+/Dmpoavf7667rjjjv8XiDVbvuwvj179qi8vNxjP6Wmpqp3794+91Mo3+dYU1lZKYfDoVatWvktF8znPRYUFhaqbdu26tq1qyZMmKDDhw/7LGv3/Xjo0CG98847Gj9+fMCysbwfT28rtmzZopMnT3rsl27duqljx44+90so32N/CDJefPPNN6qtrVW7du08lrdr107l5eVen1NeXh5U+VhSV1enyZMnq2/fvrr00kt9luvatateeeUVrVixQq+//rrq6urUp08f7d+/P4K1Na93795asGCBVq9erZdeekl79uxR//79deTIEa/l7bwPJWn58uWqqKjQuHHjfJax2z48nWtfBLOfQvk+x5ITJ07owQcf1OjRo/1egC/Yz3u0DRkyRK+99prWr1+vp556SkVFRRo6dKhqa2u9lrf7fnz11VeVnJwc8JBLLO9Hb21FeXm5mjVr1iBkB2ovXWXMPsefuL/6NQLLz8/X9u3bAx6HzcnJUU5Ojvt+nz59dNFFF+nll1/Wr3/963BXM2hDhw51/7979+7q3bu3OnXqpCVLlpj6q8hu/vznP2vo0KHKzMz0WcZu+/BMd/LkSd10000yDEMvvfSS37J2+7zfcsst7v9fdtll6t69u8477zwVFhZq4MCBUaxZeLzyyiu67bbbAg6uj+X9aLatiDR6ZLxo3bq1EhMTG4y6PnTokDIyMrw+JyMjI6jysWLixIlauXKlNmzYoKysrKCe27RpU/Xo0UO7du0KU+2s1apVK1144YU+62vXfShJe/fu1bp163TnnXcG9Ty77UPXvghmP4XyfY4FrhCzd+9erV271m9vjDeBPu+x5txzz1Xr1q191teu+1GSNm7cqJKSkqC/n1Ls7EdfbUVGRoZqampUUVHhUT5Qe+kqY/Y5/hBkvGjWrJl69uyp9evXu5fV1dVp/fr1Hn/N1peTk+NRXpLWrl3rs3y0GYahiRMn6s0339S7776rLl26BL2O2tpaffbZZ2rfvn0Yami9o0ePavfu3T7ra7d9WN/8+fPVtm1b3XDDDUE9z277sEuXLsrIyPDYT1VVVdq8ebPP/RTK9znaXCFm586dWrdundLT04NeR6DPe6zZv3+/Dh8+7LO+dtyPLn/+85/Vs2dPXX755UE/N9r7MVBb0bNnTzVt2tRjv5SUlGjfvn0+90so3+NAlYQXixcvNpKSkowFCxYYX3zxhXH33XcbrVq1MsrLyw3DMIz/+q//Mh566CF3+Q8++MBo0qSJ8dvf/tbYsWOHMWPGDKNp06bGZ599Fq1N8GvChAlGamqqUVhYaJSVlblvx48fd5c5fRtnzpxprFmzxti9e7exZcsW45ZbbjGaN29ufP7559HYhIDuv/9+o7Cw0NizZ4/xwQcfGIMGDTJat25tfPXVV4Zh2H8futTW1hodO3Y0HnzwwQaP2XEfHjlyxPjkk0+MTz75xJBk/O53vzM++eQT9xk7Tz75pNGqVStjxYoVxqeffmrk5uYaXbp0Mb777jv3Oq655hrj97//vft+oO9zpPnbxpqaGmP48OFGVlaWsW3bNo/vZ3V1tXsdp29joM97pPnbxiNHjhi/+tWvjOLiYmPPnj3GunXrjB//+MfGBRdcYJw4ccK9DjvvR5fKykrjrLPOMl566SWv64j1/WimrbjnnnuMjh07Gu+++67x8ccfGzk5OUZOTo7Herp27WoUFBS475v5HptFkPHj97//vdGxY0ejWbNmRq9evYxNmza5H/vpT39qjB071qP8kiVLjAsvvNBo1qyZcckllxjvvPNOhGtsniSvt/nz57vLnL6NkydPdr8f7dq1M66//npj69atka+8STfffLPRvn17o1mzZkaHDh2Mm2++2di1a5f7cbvvQ5c1a9YYkoySkpIGj9lxH27YsMHrZ9O1HXV1dcajjz5qtGvXzkhKSjIGDhzYYNs7depkzJgxw2OZv+9zpPnbxj179vj8fm7YsMG9jtO3MdDnPdL8bePx48eN6667zmjTpo3RtGlTo1OnTsZdd93VIJDYeT+6vPzyy0aLFi2MiooKr+uI9f1opq347rvvjHvvvdc455xzjLPOOsu48cYbjbKysgbrqf8cM99jsxw/vAAAAIDtMEYGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGAADYFkEGQNSNGzdOI0aM8Fi2bNkyNW/eXM8884zGjRsnh8Ohe+65p8Fz8/Pz5XA4NG7cuAaP3X777XrkkUckSQ6HQ8uXLw9D7QFEE0EGQMz505/+pNtuu00vvfSS7r//fklSdna2Fi9erO+++85d7sSJE1q4cKE6duzYYB21tbVauXKlhg8fHrF6A4g8ggyAmDJ79mzdd999Wrx4sW6//Xb38h//+MfKzs5WQUGBe1lBQYE6duyoHj16NFjPhx9+qKZNm+rKK6+MSL0BRAdBBkDMePDBB/XrX/9aK1eu1I033tjg8TvuuEPz589333/llVc8wk59b731loYNGyaHwxG2+gKIPoIMgJiwatUqzZ49WytWrNDAgQO9lhkzZozef/997d27V3v37tUHH3ygMWPGeC27YsUKDisBZ4Am0a4AAEhS9+7d9c0332jGjBnq1auXWrZs2aBMmzZtdMMNN2jBggUyDEM33HCDWrdu3aDcjh07dPDgQZ+BCED8oEcGQEzo0KGDCgsLdeDAAQ0ZMkRHjhzxWu6OO+7QggUL9Oqrr+qOO+7wWuatt97Stddeq+bNm4ezygBiAEEGQMzo1KmTioqKVF5e7jPMDBkyRDU1NTp58qQGDx7sdT0rVqxQbm5uuKsLIAZwaAlATMnOzlZhYaGuvvpqDR48WKtXr/Z4PDExUTt27HD//3RfffWVPv74Y7311lsNHtuzZ4+2bdvmseyCCy7Q2Wefbd0GAIgoggyAmJOVleURZtq3b+/xeEpKis/nvv322+rVq5fXsTNTp05tsGzjxo3q169f4ysNICochmEY0a4EAFhl+PDh6tevnx544IFoVwVABDBGBkBc6devn0aPHh3tagCIEHpkAACAbdEjAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbIsgAwAAbOv/AzlEhLqaQ0JsAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [0,int(max(Y_test))]\n",
        "y = [0,0]\n",
        "plt.plot(x, y, linewidth=3)\n",
        "plt.plot(Y_test, residuos,'ro')\n",
        "plt.ylabel('Resíduos')\n",
        "plt.xlabel('KM/L')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeOCCYuFQV7Y"
      },
      "source": [
        "## Propondo RNAs MLP\n",
        "\n",
        "### Escalonando os atributos\n",
        "\n",
        "O treinamento de uma rede neural artificial é mais eficiente quando os valores que lhes são fornecidos como entrada são pequenos, pois isto favorece a convergência. Isto é feito escalonando todos os atributos para o intervalo [0,1], mas precisa ser feito de maneira cautelosa, para que informações do conjunto de teste não sejam fornecidas no treinamento.\n",
        "\n",
        "Há duas estratégias para tal escalonamento: normalização e padronização. Ambas possuem características particulares, vantagens e limitações, como é possível ver aqui: https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
        "\n",
        "No nosso caso, vamos usar a padronização. Assim, com os atributos preditores do treinamento, isto é, X_train, deve-se subtrair a média e dividir pelo desvio padrão:\n",
        "\n",
        "X_train_std = (X_train - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Em seguida, o mesmo deve ser feito com os atributos preditores do conjunto de testes, mas com padronização relativa ao conjunto de treinamento:\n",
        "\n",
        "X_test_std = (X_test - np.mean(X_train))/np.std(X_train)\n",
        "\n",
        "Se todo o conjunto X for utilizado na padronização, a rede neural receberá informações do conjunto de teste por meio da média e variância utilizada para preparar os dados de treinamento, o que não é desejável."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_std = X_train.copy()\n",
        "X_test_std = X_test.copy()\n",
        "\n",
        "# Aplicando a padronização para cada coluna\n",
        "for column in X_train_std.columns:\n",
        "  scale = StandardScaler().fit(X_train_std[[column]])\n",
        "  X_train_std[column] = scale.transform(X_train_std[[column]])\n",
        "  X_test_std[column] = scale.transform(X_test_std[[column]])"
      ],
      "metadata": {
        "id": "nZ_hVDpBna5A"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Antes da padronização:\\n\")\n",
        "X_train.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOHyEFkzpcYv",
        "outputId": "502c7413-4c0d-43b6-d6a3-694ca50df725"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antes da padronização:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cylinders          4.0\n",
              "displacement     121.0\n",
              "horsepower       115.0\n",
              "weight          2795.0\n",
              "acceleration      15.7\n",
              "modelyear         78.0\n",
              "origin             2.0\n",
              "Name: 283, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Depois da padronização:\\n\")\n",
        "X_train_std.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ5IeIMVpvt-",
        "outputId": "41e70e73-8401-4199-a03c-5622b720ebe0"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depois da padronização:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cylinders      -0.903576\n",
              "displacement   -0.751447\n",
              "horsepower      0.280461\n",
              "weight         -0.252373\n",
              "acceleration    0.118976\n",
              "modelyear       0.514427\n",
              "origin          0.568091\n",
              "Name: 283, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Antes de treinar...\n",
        "\n",
        "Antes de prosseguir para a etapa de treinamento, podemos criar uma função que encapsula o processo de treinamento de uma rede MPL para este projeto:"
      ],
      "metadata": {
        "id": "3IhPFPqDuzU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ],
      "metadata": {
        "id": "2mf_KCU-wEH6"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_mlp_wrapper(x_train,\n",
        "                      x_test,\n",
        "                      y_train,\n",
        "                      y_test,\n",
        "                      activation = 'relu',\n",
        "                      solver = 'adam',\n",
        "                      n_layers=1,\n",
        "                      n_neurons=10,\n",
        "                      max_epochs = 300,\n",
        "                      verbose=True):\n",
        "  mlpr_network = MLPRegressor(max_iter=max_epochs,\n",
        "                                hidden_layer_sizes=(n_neurons,n_layers),\n",
        "                               activation=activation,\n",
        "                               solver=solver,\n",
        "                               verbose=verbose)\n",
        "  # Treinando...\n",
        "  mlpr_network.fit(x_train, y_train)\n",
        "\n",
        "  # Calculando as métricas\n",
        "  y_predict = mlpr_network.predict(x_test)\n",
        "  print_r2_score(y_test, y_predict)\n",
        "  return mlpr_network\n",
        ""
      ],
      "metadata": {
        "id": "ccSFw_xbvChg"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proposição de uma RNA MLP de Camada Única\n",
        "\n",
        "1. Consulte a documentação em https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "2. Treine uma rede neural multilayer perceptron para este problema com uma única camada e dez neurônios  \n",
        "    2.1 Utilize a função de ativação ReLU  \n",
        "    2.2 Utilize o solver Adam    \n",
        "    2.3 Imprima o passo a passo do treinamento    \n",
        "    2.4 Utilize o número máximo de épocas igual a 300\n",
        "3. Obtenha o $R^2$ do conjunto de testes"
      ],
      "metadata": {
        "id": "ezbbnc_4my-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlpr_network_1 = fit_mlp_wrapper(X_train, X_test, Y_train, Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvGFkk94mxzY",
        "outputId": "b90aa745-91fb-417e-b1da-4f24d2b76cca"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 43106.84975173\n",
            "Iteration 2, loss = 41434.72751289\n",
            "Iteration 3, loss = 39801.84184678\n",
            "Iteration 4, loss = 38245.11589022\n",
            "Iteration 5, loss = 36722.37253318\n",
            "Iteration 6, loss = 35261.03204116\n",
            "Iteration 7, loss = 33861.18934547\n",
            "Iteration 8, loss = 32525.05412229\n",
            "Iteration 9, loss = 31209.76169483\n",
            "Iteration 10, loss = 29971.98644992\n",
            "Iteration 11, loss = 28770.51833399\n",
            "Iteration 12, loss = 27649.69092028\n",
            "Iteration 13, loss = 26543.41611312\n",
            "Iteration 14, loss = 25502.70250737\n",
            "Iteration 15, loss = 24496.74938719\n",
            "Iteration 16, loss = 23552.95072693\n",
            "Iteration 17, loss = 22632.72105264\n",
            "Iteration 18, loss = 21753.51045880\n",
            "Iteration 19, loss = 20932.05416059\n",
            "Iteration 20, loss = 20131.59327840\n",
            "Iteration 21, loss = 19367.09063576\n",
            "Iteration 22, loss = 18637.11884418\n",
            "Iteration 23, loss = 17948.75042246\n",
            "Iteration 24, loss = 17283.25456494\n",
            "Iteration 25, loss = 16637.13074973\n",
            "Iteration 26, loss = 16034.66409142\n",
            "Iteration 27, loss = 15454.20305436\n",
            "Iteration 28, loss = 14893.27623136\n",
            "Iteration 29, loss = 14367.51100485\n",
            "Iteration 30, loss = 13853.00742237\n",
            "Iteration 31, loss = 13355.13335924\n",
            "Iteration 32, loss = 12891.52603533\n",
            "Iteration 33, loss = 12446.42391128\n",
            "Iteration 34, loss = 12013.40677515\n",
            "Iteration 35, loss = 11596.50569614\n",
            "Iteration 36, loss = 11191.25150371\n",
            "Iteration 37, loss = 10817.10322922\n",
            "Iteration 38, loss = 10451.36319053\n",
            "Iteration 39, loss = 10097.46159991\n",
            "Iteration 40, loss = 9760.36802046\n",
            "Iteration 41, loss = 9435.45111826\n",
            "Iteration 42, loss = 9123.81098130\n",
            "Iteration 43, loss = 8820.36068230\n",
            "Iteration 44, loss = 8533.66474064\n",
            "Iteration 45, loss = 8256.56916314\n",
            "Iteration 46, loss = 7986.81440588\n",
            "Iteration 47, loss = 7727.43168629\n",
            "Iteration 48, loss = 7479.23191821\n",
            "Iteration 49, loss = 7237.61761243\n",
            "Iteration 50, loss = 7004.10619323\n",
            "Iteration 51, loss = 6780.92708339\n",
            "Iteration 52, loss = 6567.26280009\n",
            "Iteration 53, loss = 6357.79941855\n",
            "Iteration 54, loss = 6158.33741483\n",
            "Iteration 55, loss = 5965.94132754\n",
            "Iteration 56, loss = 5779.49475354\n",
            "Iteration 57, loss = 5600.15475668\n",
            "Iteration 58, loss = 5427.25043682\n",
            "Iteration 59, loss = 5260.35171240\n",
            "Iteration 60, loss = 5100.45064874\n",
            "Iteration 61, loss = 4943.10728696\n",
            "Iteration 62, loss = 4792.78732629\n",
            "Iteration 63, loss = 4648.87285092\n",
            "Iteration 64, loss = 4506.73414631\n",
            "Iteration 65, loss = 4370.65158038\n",
            "Iteration 66, loss = 4239.28970172\n",
            "Iteration 67, loss = 4112.13073674\n",
            "Iteration 68, loss = 3988.31439688\n",
            "Iteration 69, loss = 3869.00500128\n",
            "Iteration 70, loss = 3754.39675033\n",
            "Iteration 71, loss = 3641.59112301\n",
            "Iteration 72, loss = 3532.37451751\n",
            "Iteration 73, loss = 3428.51485805\n",
            "Iteration 74, loss = 3328.77621000\n",
            "Iteration 75, loss = 3230.07509983\n",
            "Iteration 76, loss = 3133.97995088\n",
            "Iteration 77, loss = 3041.80871601\n",
            "Iteration 78, loss = 2954.53778676\n",
            "Iteration 79, loss = 2866.62654832\n",
            "Iteration 80, loss = 2783.64301067\n",
            "Iteration 81, loss = 2702.70624343\n",
            "Iteration 82, loss = 2623.22648935\n",
            "Iteration 83, loss = 2546.57120526\n",
            "Iteration 84, loss = 2472.22714476\n",
            "Iteration 85, loss = 2400.27899150\n",
            "Iteration 86, loss = 2330.83416699\n",
            "Iteration 87, loss = 2262.89727326\n",
            "Iteration 88, loss = 2196.20332161\n",
            "Iteration 89, loss = 2133.10778919\n",
            "Iteration 90, loss = 2070.85700035\n",
            "Iteration 91, loss = 2011.07528846\n",
            "Iteration 92, loss = 1953.07900669\n",
            "Iteration 93, loss = 1896.02228298\n",
            "Iteration 94, loss = 1841.69842531\n",
            "Iteration 95, loss = 1788.87308325\n",
            "Iteration 96, loss = 1736.84740760\n",
            "Iteration 97, loss = 1687.11442332\n",
            "Iteration 98, loss = 1638.56657127\n",
            "Iteration 99, loss = 1591.60514032\n",
            "Iteration 100, loss = 1545.21192794\n",
            "Iteration 101, loss = 1500.57989476\n",
            "Iteration 102, loss = 1457.15561095\n",
            "Iteration 103, loss = 1414.70649821\n",
            "Iteration 104, loss = 1373.66007975\n",
            "Iteration 105, loss = 1332.69686942\n",
            "Iteration 106, loss = 1293.74644605\n",
            "Iteration 107, loss = 1255.03245161\n",
            "Iteration 108, loss = 1218.64635394\n",
            "Iteration 109, loss = 1181.42667996\n",
            "Iteration 110, loss = 1146.66918689\n",
            "Iteration 111, loss = 1111.84725749\n",
            "Iteration 112, loss = 1079.01235132\n",
            "Iteration 113, loss = 1046.43068920\n",
            "Iteration 114, loss = 1015.15089064\n",
            "Iteration 115, loss = 984.53615122\n",
            "Iteration 116, loss = 954.83130546\n",
            "Iteration 117, loss = 926.52056056\n",
            "Iteration 118, loss = 898.50521720\n",
            "Iteration 119, loss = 871.38676574\n",
            "Iteration 120, loss = 845.29922666\n",
            "Iteration 121, loss = 819.43203026\n",
            "Iteration 122, loss = 794.84464772\n",
            "Iteration 123, loss = 770.67614838\n",
            "Iteration 124, loss = 747.05566445\n",
            "Iteration 125, loss = 724.25342652\n",
            "Iteration 126, loss = 702.05504314\n",
            "Iteration 127, loss = 680.25403108\n",
            "Iteration 128, loss = 659.68723484\n",
            "Iteration 129, loss = 639.07694365\n",
            "Iteration 130, loss = 619.40969677\n",
            "Iteration 131, loss = 599.93943781\n",
            "Iteration 132, loss = 581.35193963\n",
            "Iteration 133, loss = 563.07526281\n",
            "Iteration 134, loss = 545.93587703\n",
            "Iteration 135, loss = 528.60602547\n",
            "Iteration 136, loss = 511.87811669\n",
            "Iteration 137, loss = 495.91630670\n",
            "Iteration 138, loss = 479.97714901\n",
            "Iteration 139, loss = 465.01770922\n",
            "Iteration 140, loss = 450.15203814\n",
            "Iteration 141, loss = 435.94598474\n",
            "Iteration 142, loss = 421.91486101\n",
            "Iteration 143, loss = 408.36108448\n",
            "Iteration 144, loss = 395.30277480\n",
            "Iteration 145, loss = 382.46420698\n",
            "Iteration 146, loss = 370.15159752\n",
            "Iteration 147, loss = 358.12473761\n",
            "Iteration 148, loss = 346.55096245\n",
            "Iteration 149, loss = 335.48800019\n",
            "Iteration 150, loss = 324.33583423\n",
            "Iteration 151, loss = 313.83811159\n",
            "Iteration 152, loss = 303.67143804\n",
            "Iteration 153, loss = 293.75438965\n",
            "Iteration 154, loss = 284.19055939\n",
            "Iteration 155, loss = 274.87680634\n",
            "Iteration 156, loss = 265.85233863\n",
            "Iteration 157, loss = 257.28364122\n",
            "Iteration 158, loss = 248.67768265\n",
            "Iteration 159, loss = 240.75989101\n",
            "Iteration 160, loss = 232.74098101\n",
            "Iteration 161, loss = 225.14536437\n",
            "Iteration 162, loss = 217.81068212\n",
            "Iteration 163, loss = 210.61449805\n",
            "Iteration 164, loss = 203.69868987\n",
            "Iteration 165, loss = 196.92185562\n",
            "Iteration 166, loss = 190.56567107\n",
            "Iteration 167, loss = 184.18506300\n",
            "Iteration 168, loss = 178.13055594\n",
            "Iteration 169, loss = 172.09798408\n",
            "Iteration 170, loss = 166.46346277\n",
            "Iteration 171, loss = 160.79731537\n",
            "Iteration 172, loss = 155.38195505\n",
            "Iteration 173, loss = 150.17215971\n",
            "Iteration 174, loss = 145.13049855\n",
            "Iteration 175, loss = 140.23938845\n",
            "Iteration 176, loss = 135.49035371\n",
            "Iteration 177, loss = 130.80272349\n",
            "Iteration 178, loss = 126.43129508\n",
            "Iteration 179, loss = 122.19278391\n",
            "Iteration 180, loss = 117.95658823\n",
            "Iteration 181, loss = 113.94344296\n",
            "Iteration 182, loss = 110.14666839\n",
            "Iteration 183, loss = 106.29122744\n",
            "Iteration 184, loss = 102.67576245\n",
            "Iteration 185, loss = 99.15292291\n",
            "Iteration 186, loss = 95.83419171\n",
            "Iteration 187, loss = 92.58992778\n",
            "Iteration 188, loss = 89.39203840\n",
            "Iteration 189, loss = 86.42698092\n",
            "Iteration 190, loss = 83.45289664\n",
            "Iteration 191, loss = 80.62912853\n",
            "Iteration 192, loss = 77.96713433\n",
            "Iteration 193, loss = 75.32924753\n",
            "Iteration 194, loss = 72.83179409\n",
            "Iteration 195, loss = 70.39118088\n",
            "Iteration 196, loss = 68.10555108\n",
            "Iteration 197, loss = 65.80940462\n",
            "Iteration 198, loss = 63.67708501\n",
            "Iteration 199, loss = 61.58229853\n",
            "Iteration 200, loss = 59.61209635\n",
            "Iteration 201, loss = 57.76042050\n",
            "Iteration 202, loss = 55.88208345\n",
            "Iteration 203, loss = 54.10291025\n",
            "Iteration 204, loss = 52.41865297\n",
            "Iteration 205, loss = 50.78899724\n",
            "Iteration 206, loss = 49.25505380\n",
            "Iteration 207, loss = 47.74390344\n",
            "Iteration 208, loss = 46.29149090\n",
            "Iteration 209, loss = 44.87276386\n",
            "Iteration 210, loss = 43.55958749\n",
            "Iteration 211, loss = 42.22852162\n",
            "Iteration 212, loss = 41.05073709\n",
            "Iteration 213, loss = 39.82090646\n",
            "Iteration 214, loss = 38.64528765\n",
            "Iteration 215, loss = 37.59021348\n",
            "Iteration 216, loss = 36.53106245\n",
            "Iteration 217, loss = 35.51491915\n",
            "Iteration 218, loss = 34.54070395\n",
            "Iteration 219, loss = 33.67863015\n",
            "Iteration 220, loss = 32.78159751\n",
            "Iteration 221, loss = 31.95599563\n",
            "Iteration 222, loss = 31.15674155\n",
            "Iteration 223, loss = 30.42266980\n",
            "Iteration 224, loss = 29.67246942\n",
            "Iteration 225, loss = 28.99984666\n",
            "Iteration 226, loss = 28.32860169\n",
            "Iteration 227, loss = 27.67887023\n",
            "Iteration 228, loss = 27.04324773\n",
            "Iteration 229, loss = 26.48639607\n",
            "Iteration 230, loss = 25.89590828\n",
            "Iteration 231, loss = 25.35046796\n",
            "Iteration 232, loss = 24.84489255\n",
            "Iteration 233, loss = 24.33453633\n",
            "Iteration 234, loss = 23.86991397\n",
            "Iteration 235, loss = 23.40935197\n",
            "Iteration 236, loss = 22.99028531\n",
            "Iteration 237, loss = 22.57099679\n",
            "Iteration 238, loss = 22.18323550\n",
            "Iteration 239, loss = 21.81154863\n",
            "Iteration 240, loss = 21.46651974\n",
            "Iteration 241, loss = 21.12874178\n",
            "Iteration 242, loss = 20.80743929\n",
            "Iteration 243, loss = 20.50072220\n",
            "Iteration 244, loss = 20.20773765\n",
            "Iteration 245, loss = 19.94184239\n",
            "Iteration 246, loss = 19.65734615\n",
            "Iteration 247, loss = 19.41263851\n",
            "Iteration 248, loss = 19.16519741\n",
            "Iteration 249, loss = 18.92022795\n",
            "Iteration 250, loss = 18.69953476\n",
            "Iteration 251, loss = 18.49581778\n",
            "Iteration 252, loss = 18.27794767\n",
            "Iteration 253, loss = 18.08867689\n",
            "Iteration 254, loss = 17.89079339\n",
            "Iteration 255, loss = 17.72851554\n",
            "Iteration 256, loss = 17.55757279\n",
            "Iteration 257, loss = 17.39598867\n",
            "Iteration 258, loss = 17.25637638\n",
            "Iteration 259, loss = 17.10977743\n",
            "Iteration 260, loss = 16.97058188\n",
            "Iteration 261, loss = 16.84237379\n",
            "Iteration 262, loss = 16.72230406\n",
            "Iteration 263, loss = 16.60935247\n",
            "Iteration 264, loss = 16.49202935\n",
            "Iteration 265, loss = 16.39526498\n",
            "Iteration 266, loss = 16.28665244\n",
            "Iteration 267, loss = 16.19247450\n",
            "Iteration 268, loss = 16.10639314\n",
            "Iteration 269, loss = 16.01866707\n",
            "Iteration 270, loss = 15.93970978\n",
            "Iteration 271, loss = 15.86532072\n",
            "Iteration 272, loss = 15.78929473\n",
            "Iteration 273, loss = 15.71482513\n",
            "Iteration 274, loss = 15.65712195\n",
            "Iteration 275, loss = 15.59356910\n",
            "Iteration 276, loss = 15.53263485\n",
            "Iteration 277, loss = 15.48023814\n",
            "Iteration 278, loss = 15.42040662\n",
            "Iteration 279, loss = 15.37052317\n",
            "Iteration 280, loss = 15.32212726\n",
            "Iteration 281, loss = 15.27899615\n",
            "Iteration 282, loss = 15.23111641\n",
            "Iteration 283, loss = 15.19366667\n",
            "Iteration 284, loss = 15.15292914\n",
            "Iteration 285, loss = 15.11713282\n",
            "Iteration 286, loss = 15.08511565\n",
            "Iteration 287, loss = 15.05064559\n",
            "Iteration 288, loss = 15.02075131\n",
            "Iteration 289, loss = 14.99308633\n",
            "Iteration 290, loss = 14.96091983\n",
            "Iteration 291, loss = 14.94037878\n",
            "Iteration 292, loss = 14.91235808\n",
            "Iteration 293, loss = 14.88726734\n",
            "Iteration 294, loss = 14.86412040\n",
            "Iteration 295, loss = 14.84213826\n",
            "Iteration 296, loss = 14.82022799\n",
            "Iteration 297, loss = 14.79871659\n",
            "Iteration 298, loss = 14.78166520\n",
            "Iteration 299, loss = 14.76311452\n",
            "Iteration 300, loss = 14.74682445\n",
            "======== Métricas ==========\n",
            "R2 Score: -1.9171300307868786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "l5yI_eE2QV7Y"
      },
      "source": [
        "### Proposição de uma RNA MLP com duas camadas ocultas\n",
        "\n",
        "1. Treine uma rede neural multilayer perceptron para este problema com duas camadas ocultas, com número de neurônios à sua escolha  \n",
        "    2.1 Utilize a função de ativação ReLU  \n",
        "    2.2 Utilize o solver Adam    \n",
        "    2.3 Imprima o passo a passo do treinamento    \n",
        "    2.4 Utilize o número máximo de épocas igual a 300\n",
        "2. Obtenha o $R^2$ do conjunto de testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "QBRAay8pQV7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d11c5d8-47d5-42dc-e3ea-cd90ea1b100a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 36219.00903734\n",
            "Iteration 2, loss = 29734.97546205\n",
            "Iteration 3, loss = 24063.39309244\n",
            "Iteration 4, loss = 19053.98140758\n",
            "Iteration 5, loss = 14664.08737625\n",
            "Iteration 6, loss = 10982.38725398\n",
            "Iteration 7, loss = 7893.70530935\n",
            "Iteration 8, loss = 5452.39637793\n",
            "Iteration 9, loss = 3525.52475315\n",
            "Iteration 10, loss = 2114.96904671\n",
            "Iteration 11, loss = 1119.16553869\n",
            "Iteration 12, loss = 494.03339392\n",
            "Iteration 13, loss = 158.18750646\n",
            "Iteration 14, loss = 68.51391542\n",
            "Iteration 15, loss = 66.64886288\n",
            "Iteration 16, loss = 66.64050228\n",
            "Iteration 17, loss = 66.63315899\n",
            "Iteration 18, loss = 66.62666152\n",
            "Iteration 19, loss = 66.62093236\n",
            "Iteration 20, loss = 66.61581138\n",
            "Iteration 21, loss = 66.61109139\n",
            "Iteration 22, loss = 66.60683656\n",
            "Iteration 23, loss = 66.60288324\n",
            "Iteration 24, loss = 66.59916704\n",
            "Iteration 25, loss = 66.59569025\n",
            "Iteration 26, loss = 66.59235326\n",
            "Iteration 27, loss = 66.58916787\n",
            "Iteration 28, loss = 66.58605949\n",
            "Iteration 29, loss = 66.58303277\n",
            "Iteration 30, loss = 66.58007161\n",
            "Iteration 31, loss = 66.57714231\n",
            "Iteration 32, loss = 66.57425214\n",
            "Iteration 33, loss = 66.57133528\n",
            "Iteration 34, loss = 66.56846630\n",
            "Iteration 35, loss = 66.56558540\n",
            "Iteration 36, loss = 66.56270043\n",
            "Iteration 37, loss = 66.55980600\n",
            "Iteration 38, loss = 66.55688472\n",
            "Iteration 39, loss = 66.55393409\n",
            "Iteration 40, loss = 66.55099474\n",
            "Iteration 41, loss = 66.54801210\n",
            "Iteration 42, loss = 66.54499341\n",
            "Iteration 43, loss = 66.54198069\n",
            "Iteration 44, loss = 66.53888531\n",
            "Iteration 45, loss = 66.53580774\n",
            "Iteration 46, loss = 66.53266770\n",
            "Iteration 47, loss = 66.52949155\n",
            "Iteration 48, loss = 66.52628865\n",
            "Iteration 49, loss = 66.52305748\n",
            "Iteration 50, loss = 66.51979151\n",
            "Iteration 51, loss = 66.51648202\n",
            "Iteration 52, loss = 66.51314059\n",
            "Iteration 53, loss = 66.50977886\n",
            "Iteration 54, loss = 66.50637534\n",
            "Iteration 55, loss = 66.50294214\n",
            "Iteration 56, loss = 66.49948547\n",
            "Iteration 57, loss = 66.49600147\n",
            "Iteration 58, loss = 66.49251459\n",
            "Iteration 59, loss = 66.48893035\n",
            "Iteration 60, loss = 66.48538670\n",
            "Iteration 61, loss = 66.48178034\n",
            "Iteration 62, loss = 66.47815064\n",
            "Iteration 63, loss = 66.47448758\n",
            "Iteration 64, loss = 66.47079666\n",
            "Iteration 65, loss = 66.46705646\n",
            "Iteration 66, loss = 66.46331301\n",
            "Iteration 67, loss = 66.45951238\n",
            "Iteration 68, loss = 66.45566094\n",
            "Iteration 69, loss = 66.45182738\n",
            "Iteration 70, loss = 66.44791902\n",
            "Iteration 71, loss = 66.44400966\n",
            "Iteration 72, loss = 66.44001721\n",
            "Iteration 73, loss = 66.43611168\n",
            "Iteration 74, loss = 66.43203663\n",
            "Iteration 75, loss = 66.42800857\n",
            "Iteration 76, loss = 66.42398445\n",
            "Iteration 77, loss = 66.41986139\n",
            "Iteration 78, loss = 66.41575137\n",
            "Iteration 79, loss = 66.41158625\n",
            "Iteration 80, loss = 66.40742094\n",
            "Iteration 81, loss = 66.40321211\n",
            "Iteration 82, loss = 66.39896811\n",
            "Iteration 83, loss = 66.39476239\n",
            "Iteration 84, loss = 66.39042473\n",
            "Iteration 85, loss = 66.38614981\n",
            "Iteration 86, loss = 66.38181230\n",
            "Iteration 87, loss = 66.37745349\n",
            "Iteration 88, loss = 66.37307989\n",
            "Iteration 89, loss = 66.36867388\n",
            "Iteration 90, loss = 66.36422530\n",
            "Iteration 91, loss = 66.35977844\n",
            "Iteration 92, loss = 66.35529604\n",
            "Iteration 93, loss = 66.35082032\n",
            "Iteration 94, loss = 66.34625759\n",
            "Iteration 95, loss = 66.34168691\n",
            "Iteration 96, loss = 66.33713258\n",
            "Iteration 97, loss = 66.33251356\n",
            "Iteration 98, loss = 66.32789610\n",
            "Iteration 99, loss = 66.32326659\n",
            "Iteration 100, loss = 66.31857803\n",
            "Iteration 101, loss = 66.31391826\n",
            "Iteration 102, loss = 66.30919272\n",
            "Iteration 103, loss = 66.30446136\n",
            "Iteration 104, loss = 66.29968434\n",
            "Iteration 105, loss = 66.29486387\n",
            "Iteration 106, loss = 66.29008923\n",
            "Iteration 107, loss = 66.28522577\n",
            "Iteration 108, loss = 66.28033956\n",
            "Iteration 109, loss = 66.27542679\n",
            "Iteration 110, loss = 66.27050168\n",
            "Iteration 111, loss = 66.26552816\n",
            "Iteration 112, loss = 66.26053775\n",
            "Iteration 113, loss = 66.25554280\n",
            "Iteration 114, loss = 66.25050502\n",
            "Iteration 115, loss = 66.24547192\n",
            "Iteration 116, loss = 66.24035755\n",
            "Iteration 117, loss = 66.23524626\n",
            "Iteration 118, loss = 66.23014726\n",
            "Iteration 119, loss = 66.22498650\n",
            "Iteration 120, loss = 66.21980705\n",
            "Iteration 121, loss = 66.21461070\n",
            "Iteration 122, loss = 66.20936687\n",
            "Iteration 123, loss = 66.20417262\n",
            "Iteration 124, loss = 66.19887784\n",
            "Iteration 125, loss = 66.19360061\n",
            "Iteration 126, loss = 66.18828590\n",
            "Iteration 127, loss = 66.18296410\n",
            "Iteration 128, loss = 66.17760455\n",
            "Iteration 129, loss = 66.17225339\n",
            "Iteration 130, loss = 66.16686783\n",
            "Iteration 131, loss = 66.16147271\n",
            "Iteration 132, loss = 66.15600334\n",
            "Iteration 133, loss = 66.15059005\n",
            "Iteration 134, loss = 66.14512758\n",
            "Iteration 135, loss = 66.13959053\n",
            "Iteration 136, loss = 66.13406731\n",
            "Iteration 137, loss = 66.12858833\n",
            "Iteration 138, loss = 66.12298146\n",
            "Iteration 139, loss = 66.11738134\n",
            "Iteration 140, loss = 66.11176180\n",
            "Iteration 141, loss = 66.10612522\n",
            "Iteration 142, loss = 66.10050069\n",
            "Iteration 143, loss = 66.09479687\n",
            "Iteration 144, loss = 66.08909938\n",
            "Iteration 145, loss = 66.08341645\n",
            "Iteration 146, loss = 66.07766363\n",
            "Iteration 147, loss = 66.07192429\n",
            "Iteration 148, loss = 66.06611539\n",
            "Iteration 149, loss = 66.06033890\n",
            "Iteration 150, loss = 66.05457557\n",
            "Iteration 151, loss = 66.04873592\n",
            "Iteration 152, loss = 66.04285941\n",
            "Iteration 153, loss = 66.03702106\n",
            "Iteration 154, loss = 66.03111780\n",
            "Iteration 155, loss = 66.02527619\n",
            "Iteration 156, loss = 66.01934182\n",
            "Iteration 157, loss = 66.01342596\n",
            "Iteration 158, loss = 66.00741475\n",
            "Iteration 159, loss = 66.00151215\n",
            "Iteration 160, loss = 65.99544791\n",
            "Iteration 161, loss = 65.98945439\n",
            "Iteration 162, loss = 65.98339092\n",
            "Iteration 163, loss = 65.97735427\n",
            "Iteration 164, loss = 65.97124751\n",
            "Iteration 165, loss = 65.96513074\n",
            "Iteration 166, loss = 65.95901422\n",
            "Iteration 167, loss = 65.95283082\n",
            "Iteration 168, loss = 65.94665115\n",
            "Iteration 169, loss = 65.94049513\n",
            "Iteration 170, loss = 65.93424940\n",
            "Iteration 171, loss = 65.92799304\n",
            "Iteration 172, loss = 65.92176834\n",
            "Iteration 173, loss = 65.91550843\n",
            "Iteration 174, loss = 65.90921376\n",
            "Iteration 175, loss = 65.90288594\n",
            "Iteration 176, loss = 65.89659620\n",
            "Iteration 177, loss = 65.89025322\n",
            "Iteration 178, loss = 65.88390807\n",
            "Iteration 179, loss = 65.87748791\n",
            "Iteration 180, loss = 65.87112460\n",
            "Iteration 181, loss = 65.86466100\n",
            "Iteration 182, loss = 65.85826856\n",
            "Iteration 183, loss = 65.85175183\n",
            "Iteration 184, loss = 65.84530334\n",
            "Iteration 185, loss = 65.83879307\n",
            "Iteration 186, loss = 65.83225831\n",
            "Iteration 187, loss = 65.82574955\n",
            "Iteration 188, loss = 65.81917184\n",
            "Iteration 189, loss = 65.81262431\n",
            "Iteration 190, loss = 65.80600106\n",
            "Iteration 191, loss = 65.79942521\n",
            "Iteration 192, loss = 65.79278171\n",
            "Iteration 193, loss = 65.78612008\n",
            "Iteration 194, loss = 65.77950066\n",
            "Iteration 195, loss = 65.77276572\n",
            "Iteration 196, loss = 65.76611198\n",
            "Iteration 197, loss = 65.75941548\n",
            "Iteration 198, loss = 65.75264582\n",
            "Iteration 199, loss = 65.74589212\n",
            "Iteration 200, loss = 65.73912672\n",
            "Iteration 201, loss = 65.73230566\n",
            "Iteration 202, loss = 65.72549948\n",
            "Iteration 203, loss = 65.71868455\n",
            "Iteration 204, loss = 65.71183169\n",
            "Iteration 205, loss = 65.70498271\n",
            "Iteration 206, loss = 65.69804929\n",
            "Iteration 207, loss = 65.69117678\n",
            "Iteration 208, loss = 65.68428903\n",
            "Iteration 209, loss = 65.67732736\n",
            "Iteration 210, loss = 65.67040906\n",
            "Iteration 211, loss = 65.66348320\n",
            "Iteration 212, loss = 65.65647151\n",
            "Iteration 213, loss = 65.64944246\n",
            "Iteration 214, loss = 65.64250058\n",
            "Iteration 215, loss = 65.63543939\n",
            "Iteration 216, loss = 65.62840418\n",
            "Iteration 217, loss = 65.62132766\n",
            "Iteration 218, loss = 65.61422928\n",
            "Iteration 219, loss = 65.60716256\n",
            "Iteration 220, loss = 65.60004762\n",
            "Iteration 221, loss = 65.59292879\n",
            "Iteration 222, loss = 65.58573071\n",
            "Iteration 223, loss = 65.57857389\n",
            "Iteration 224, loss = 65.57143253\n",
            "Iteration 225, loss = 65.56423744\n",
            "Iteration 226, loss = 65.55699650\n",
            "Iteration 227, loss = 65.54977133\n",
            "Iteration 228, loss = 65.54256941\n",
            "Iteration 229, loss = 65.53525572\n",
            "Iteration 230, loss = 65.52798807\n",
            "Iteration 231, loss = 65.52066954\n",
            "Iteration 232, loss = 65.51333291\n",
            "Iteration 233, loss = 65.50599034\n",
            "Iteration 234, loss = 65.49858500\n",
            "Iteration 235, loss = 65.49121620\n",
            "Iteration 236, loss = 65.48378300\n",
            "Iteration 237, loss = 65.47638646\n",
            "Iteration 238, loss = 65.46888833\n",
            "Iteration 239, loss = 65.46144476\n",
            "Iteration 240, loss = 65.45401141\n",
            "Iteration 241, loss = 65.44651491\n",
            "Iteration 242, loss = 65.43897382\n",
            "Iteration 243, loss = 65.43147185\n",
            "Iteration 244, loss = 65.42395104\n",
            "Iteration 245, loss = 65.41639483\n",
            "Iteration 246, loss = 65.40877931\n",
            "Iteration 247, loss = 65.40122370\n",
            "Iteration 248, loss = 65.39359034\n",
            "Iteration 249, loss = 65.38596618\n",
            "Iteration 250, loss = 65.37830350\n",
            "Iteration 251, loss = 65.37063863\n",
            "Iteration 252, loss = 65.36301806\n",
            "Iteration 253, loss = 65.35524583\n",
            "Iteration 254, loss = 65.34758917\n",
            "Iteration 255, loss = 65.33990392\n",
            "Iteration 256, loss = 65.33219905\n",
            "Iteration 257, loss = 65.32441131\n",
            "Iteration 258, loss = 65.31671359\n",
            "Iteration 259, loss = 65.30898801\n",
            "Iteration 260, loss = 65.30121373\n",
            "Iteration 261, loss = 65.29343095\n",
            "Iteration 262, loss = 65.28568029\n",
            "Iteration 263, loss = 65.27784754\n",
            "Iteration 264, loss = 65.27003062\n",
            "Iteration 265, loss = 65.26218423\n",
            "Iteration 266, loss = 65.25432876\n",
            "Iteration 267, loss = 65.24644800\n",
            "Iteration 268, loss = 65.23851854\n",
            "Iteration 269, loss = 65.23057466\n",
            "Iteration 270, loss = 65.22269721\n",
            "Iteration 271, loss = 65.21467523\n",
            "Iteration 272, loss = 65.20669938\n",
            "Iteration 273, loss = 65.19873085\n",
            "Iteration 274, loss = 65.19075494\n",
            "Iteration 275, loss = 65.18275944\n",
            "Iteration 276, loss = 65.17469586\n",
            "Iteration 277, loss = 65.16671409\n",
            "Iteration 278, loss = 65.15864552\n",
            "Iteration 279, loss = 65.15060342\n",
            "Iteration 280, loss = 65.14256888\n",
            "Iteration 281, loss = 65.13449039\n",
            "Iteration 282, loss = 65.12629872\n",
            "Iteration 283, loss = 65.11826529\n",
            "Iteration 284, loss = 65.11007140\n",
            "Iteration 285, loss = 65.10190336\n",
            "Iteration 286, loss = 65.09378426\n",
            "Iteration 287, loss = 65.08552742\n",
            "Iteration 288, loss = 65.07736669\n",
            "Iteration 289, loss = 65.06911232\n",
            "Iteration 290, loss = 65.06085463\n",
            "Iteration 291, loss = 65.05259810\n",
            "Iteration 292, loss = 65.04433456\n",
            "Iteration 293, loss = 65.03606918\n",
            "Iteration 294, loss = 65.02763731\n",
            "Iteration 295, loss = 65.01939747\n",
            "Iteration 296, loss = 65.01103824\n",
            "Iteration 297, loss = 65.00270662\n",
            "Iteration 298, loss = 64.99423850\n",
            "Iteration 299, loss = 64.98589375\n",
            "Iteration 300, loss = 64.97752171\n",
            "======== Métricas ==========\n",
            "R2 Score: -11.978011977513754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "mlpr_network_2 = fit_mlp_wrapper(X_train, X_test, Y_train, Y_test, n_layers=2, n_neurons=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYtIpprtQV7Y"
      },
      "source": [
        "### Para Discussão\n",
        "\n",
        "- Qual melhor modelo para este problema?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "pSExq7ukQV7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15480141-ae73-4d12-8976-374a93b4618a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+---------------------+\n",
            "|                    Nome                   |       R2 Score      |\n",
            "+-------------------------------------------+---------------------+\n",
            "|              LinearRegression             |  0.8312579780256858 |\n",
            "| MLPRegressor [n_layers = 1, n_neurons=10] | -1.9171300307868786 |\n",
            "| MLPRegressor [n_layers = 2, n_neurons=20] | -11.978011977513754 |\n",
            "+-------------------------------------------+---------------------+\n"
          ]
        }
      ],
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "linear_score = r2_score(Y_test, lr_model.predict(X_test))\n",
        "mlpr_1_score = r2_score(Y_test, mlpr_network_1.predict(X_test))\n",
        "mlpr_2_score = r2_score(Y_test, mlpr_network_2.predict(X_test))\n",
        "\n",
        "table.field_names = ['Nome', 'R2 Score']\n",
        "table.add_row(['LinearRegression', linear_score])\n",
        "table.add_row(['MLPRegressor [n_layers = 1, n_neurons=10]', mlpr_1_score])\n",
        "table.add_row(['MLPRegressor [n_layers = 2, n_neurons=20]', mlpr_2_score])\n",
        "\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando o $R^2$ _score_ das redes MLP com a pontuação do modelo de regressão linear, podemos notar que **o modelo de regressão linear acertou mais exemplos** do conjunto de testes, superando consideralmente os resultados das redes neurais MLP.\n",
        "\n",
        "Uma explicação para esta considerável diferença de resultados está no fato de haver poucos exemplos no _dataset_ (um pouco menos de 400 exemplos após a etapa de pré-processamento), dificultando a convergência das redes MLP.\n",
        "\n",
        "Além disso, a [documentação da função](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) `r2_score` da biblioteca `scikit-learn` ainda descreve que \"a melhor pontuação possível é 1 e pode ser negativa (visto que o modelo pode ser arbitrariamente pior)\", explicando o motivo das pontuações negativas obtidas nas previsões."
      ],
      "metadata": {
        "id": "WlTMo8he5l6Y"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}